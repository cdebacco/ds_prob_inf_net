{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "829a333c-75cf-48c2-88a5-0ecbefacc509",
   "metadata": {},
   "source": [
    "# L3: VI and Gaussian mixture model (GMM)\n",
    "\n",
    "Here we explore how to use Variational Inference to learn parameters in the GMM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111bcd99-22e9-4b7c-88f8-fe3219a7fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bf21c4-bca0-421f-8c44-2e565c3c3590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f2f442-f113-4735-bf94-b05d91feec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../src/')\n",
    "import tools as tl\n",
    "import plot as viz\n",
    "# import pysbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f7d6bc-ed75-4214-a153-b0f5580dbddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "colormap = plt.cm.tab10\n",
    "colors = {i: colormap(i) for i in range(20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf121a3-9596-4103-b8bc-603928245c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir_fig = '../figures/'\n",
    "lecture_id = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ca535-63c6-4f14-96be-516d2d4c01f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "prng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35c50f1-c6d1-46b7-8d74-fa5506cd0184",
   "metadata": {},
   "source": [
    "# 1. Generate data from GMM\n",
    "Let's generate some synthetic data from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6bf078-836c-43ee-80c4-cec1e6f8421f",
   "metadata": {},
   "source": [
    "#### Ground truth parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b0e21c-d644-4caf-8079-6dcd4cc2e799",
   "metadata": {},
   "outputs": [],
   "source": [
    "K=3\n",
    "SAMPLE=1000 # number of data per cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6eb690-9fc5-4713-8eea-5baf545eb47d",
   "metadata": {},
   "source": [
    "#### Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be95708a-1a82-4095-a3db-ae9d2df2bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_components = K\n",
    "mu_arr = [0,1.,5.]\n",
    "\n",
    "# Ground truth cluster assignments\n",
    "c_GT = np.zeros((K * SAMPLE,K))\n",
    "c_GT[np.arange(SAMPLE),0]=1\n",
    "c_GT[np.arange(SAMPLE,SAMPLE*2),1]=1\n",
    "c_GT[np.arange(SAMPLE*2,SAMPLE*3),2]=1\n",
    "\n",
    "# Ground truth X\n",
    "assert np.all(np.sum(c_GT,axis=1)==1)\n",
    "X = prng.normal(loc=mu_arr[0], scale=1, size=SAMPLE)\n",
    "for i, mu in enumerate(mu_arr[1:]):\n",
    "    X = np.append(X, prng.normal(loc=mu, scale=1, size=SAMPLE))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52216e1-9f8c-4916-ac72-dd2931476cf4",
   "metadata": {},
   "source": [
    "## 1.1 Plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55cb4b1-cffc-4f8f-88a0-f88b0f27b05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "sns.histplot(X[:SAMPLE], ax=ax,kde=True)\n",
    "sns.histplot(X[SAMPLE:SAMPLE*2], ax=ax,kde=True)\n",
    "sns.histplot(X[SAMPLE*2:], ax=ax,kde=True)\n",
    "# sns.distplot(X[:SAMPLE], ax=ax, rug=True)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "filename = tl.get_filename(\"GMMexample\",lecture_id=lecture_id)\n",
    "filename = None\n",
    "tl.savefig(plt,outfile = filename,outdir = outdir_fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47587214-6db3-4182-ac22-194420e0b268",
   "metadata": {},
   "source": [
    "# 2. Implement CAVI updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf960589-ad8a-4e16-9b7d-f2330a9e0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class UGMM(object):\n",
    "    '''Univariate GMM with CAVI'''\n",
    "    def __init__(self, X, K=2, sigma=1):\n",
    "        self.X = X\n",
    "        self.K = K\n",
    "        self.N = self.X.shape[0]\n",
    "        self.sigma2 = sigma**2\n",
    "\n",
    "    def _init(self):\n",
    "        self.phi = np.random.dirichlet([np.random.random()*np.random.randint(1, 10)]*self.K, self.N)\n",
    "        self.m = np.random.randint(int(self.X.min()), high=int(self.X.max()), size=self.K).astype(float)\n",
    "        self.m += self.X.max()*np.random.random(self.K)\n",
    "        self.s2 = np.ones(self.K) * np.random.random(self.K)\n",
    "        print('Init mean')\n",
    "        print(self.m)\n",
    "        print('Init s2')\n",
    "        print(self.s2)\n",
    "\n",
    "    def get_elbo(self):\n",
    "        t1 = np.log(self.s2) - self.m/self.sigma2\n",
    "        t1 = t1.sum()\n",
    "        t2 = -0.5*np.add.outer(self.X**2, self.s2+self.m**2)\n",
    "        t2 += np.outer(self.X, self.m)\n",
    "        t2 -= np.log(self.phi)\n",
    "        t2 *= self.phi\n",
    "        t2 = t2.sum()\n",
    "        return t1 + t2\n",
    "\n",
    "    def fit(self, max_iter=100, tol=1e-10):\n",
    "        self._init()\n",
    "        self.elbo_values = [self.get_elbo()]\n",
    "        self.m_history = [self.m]\n",
    "        self.s2_history = [self.s2]\n",
    "        print(f\"it mean\")\n",
    "        for iter_ in range(1, max_iter+1):\n",
    "            self._cavi()\n",
    "            self.m_history.append(self.m)\n",
    "            self.s2_history.append(self.s2)\n",
    "            self.elbo_values.append(self.get_elbo())\n",
    "            if iter_ % 5 == 0:\n",
    "                print(iter_, self.m_history[iter_])\n",
    "            if np.abs(self.elbo_values[-2] - self.elbo_values[-1]) <= tol:\n",
    "                print('ELBO converged with ll %.3f at iteration %d'%(self.elbo_values[-1],\n",
    "                                                                     iter_))\n",
    "                break\n",
    "\n",
    "        if iter_ == max_iter:\n",
    "            print('ELBO ended with ll %.3f'%(self.elbo_values[-1]))\n",
    "\n",
    "\n",
    "    def _cavi(self):\n",
    "        self._update_phi()\n",
    "        self._update_mu()\n",
    "\n",
    "    def _update_phi(self):\n",
    "        t1 = np.outer(self.X, self.m)\n",
    "        t2 = -(0.5*self.m**2 + 0.5*self.s2)\n",
    "        exponent = t1 + t2[np.newaxis, :]\n",
    "        self.phi = np.exp(exponent)\n",
    "        self.phi = self.phi / self.phi.sum(1)[:, np.newaxis]\n",
    "\n",
    "    def _update_mu(self):\n",
    "        self.m = (self.phi*self.X[:, np.newaxis]).sum(0) * (1/self.sigma2 + self.phi.sum(0))**(-1)\n",
    "        assert self.m.size == self.K\n",
    "        #print(self.m)\n",
    "        self.s2 = (1/self.sigma2 + self.phi.sum(0))**(-1)\n",
    "        assert self.s2.size == self.K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc90f34b-a20f-4cb1-8d23-0a4ad914996d",
   "metadata": {},
   "source": [
    "# 3. Fit model to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2f77f5-9609-406e-a282-0727c45944d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ugmm = UGMM(X, 3)\n",
    "ugmm.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481b7443-2bb4-4755-ba98-42aff48d5e8c",
   "metadata": {},
   "source": [
    "## 3.1 Plot results at convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e086ac-4547-49ce-8dfa-fdd30a0c238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_colors=[ [] for k in range(K)]\n",
    "for i in range(SAMPLE*K):\n",
    "    q=np.argmax(ugmm.phi[i])\n",
    "    inferred_colors[q].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247d5c46-75d6-4b01-b8ea-b18c6f0059e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "sns.histplot(X[:SAMPLE], ax=ax, kde=True,label='Data')\n",
    "sns.histplot(prng.normal(ugmm.m[0], 1, SAMPLE),color=colors[0], kde=True,line_kws={'ls':'--'},alpha=0.3,label='Inferred')\n",
    "sns.histplot(X[SAMPLE:SAMPLE*2], ax=ax, kde=True)\n",
    "sns.histplot(prng.normal(ugmm.m[1], 1, SAMPLE),ax=ax,color=colors[4] , kde=True,line_kws={'ls':'--'},alpha=0.1)\n",
    "sns.histplot(X[SAMPLE*2:], ax=ax, kde=True)\n",
    "sns.histplot(prng.normal(ugmm.m[2], 1, SAMPLE),ax=ax,color=colors[2],kde=True,line_kws={'ls':'--'},alpha=0.1)\n",
    "\n",
    "plt.figtext(0.15,0.75,f't = 78\\n(convergence)',fontsize=14)\n",
    "plt.legend(loc='best')\n",
    "\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "filename = tl.get_filename(\"GMMexample_itConv\",lecture_id=lecture_id)\n",
    "filename = None\n",
    "tl.savefig(plt,outfile = filename,outdir = outdir_fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8279269-4259-4220-9a93-cc0b699e6653",
   "metadata": {},
   "source": [
    "# 4. Analyze ELBO\n",
    "How did the ELBO evolve during training?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3437de96-8000-401d-8494-7df25ae853d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs=20\n",
    "\n",
    "# Focus iteration points\n",
    "it1=8\n",
    "it2=15\n",
    "# ---------\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(np.arange(len(ugmm.elbo_values)),ugmm.elbo_values)\n",
    "plt.plot(np.arange(len(ugmm.elbo_values)),ugmm.elbo_values, alpha=0.3)\n",
    "plt.scatter(it1,ugmm.elbo_values[it1],marker='s',facecolors='none',edgecolors='r',s=200, linewidth=3)\n",
    "plt.scatter(it2,ugmm.elbo_values[it2],marker='s',facecolors='none',edgecolors='r',s=200, linewidth=3)\n",
    "plt.xlim([-1,25])\n",
    "# plt.ylim([-850,-100])\n",
    "plt.xlabel('Iterations',fontsize=fs)\n",
    "plt.ylabel('ELBO',fontsize=fs)\n",
    "\n",
    "\n",
    "filename = tl.get_filename(\"GMMexample_ELBO\",lecture_id=lecture_id)\n",
    "filename = None\n",
    "tl.savefig(plt,outfile = filename,outdir = outdir_fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baafd48-b748-42ed-9232-fbee4dd1fe5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T16:03:52.645960Z",
     "iopub.status.busy": "2025-04-22T16:03:52.645496Z",
     "iopub.status.idle": "2025-04-22T16:03:52.674544Z",
     "shell.execute_reply": "2025-04-22T16:03:52.673683Z",
     "shell.execute_reply.started": "2025-04-22T16:03:52.645931Z"
    }
   },
   "source": [
    "We have highlighted two interesting points, where the ELBO changes more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9908261e-e9bb-41fa-87a5-9c14df90e51e",
   "metadata": {},
   "source": [
    "## 4.1 Plot changing points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22290946-2a5d-45d3-a5c3-dd0c8c3cae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in [0,it1,it2]:\n",
    "    fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    \n",
    "    sns.histplot(X[:SAMPLE], ax=ax, kde=True)\n",
    "    sns.histplot(prng.normal(ugmm.m_history[it][0], 1, SAMPLE),color=colors[0], kde=True,line_kws={'ls':'--'},alpha=0.1)\n",
    "    sns.histplot(X[SAMPLE:SAMPLE*2], ax=ax, kde=True)\n",
    "    sns.histplot(prng.normal(ugmm.m_history[it][1], 1, SAMPLE),ax=ax,color=colors[4] , kde=True,line_kws={'ls':'--'},alpha=0.1)\n",
    "    sns.histplot(X[SAMPLE*2:], ax=ax, kde=True)\n",
    "    sns.histplot(prng.normal(ugmm.m_history[it][2], 1, SAMPLE),ax=ax,color=colors[2],kde=True,line_kws={'ls':'--'},alpha=0.1)\n",
    "    \n",
    "    plt.figtext(0.8,0.8,f't = {it}',fontsize=20)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('Count')\n",
    "    \n",
    "    filename = tl.get_filename(f\"GMMexample_it{it}\",lecture_id=lecture_id)\n",
    "    filename = None\n",
    "    tl.savefig(plt,outfile = filename,outdir = outdir_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27970803-d513-4225-83b7-0d7a1ffd0e96",
   "metadata": {},
   "source": [
    "# 5. Evaluate model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0ddcb4-1d39-4dc9-94ec-2ae00468ab65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-22T16:11:54.450814Z",
     "iopub.status.busy": "2025-04-22T16:11:54.450411Z",
     "iopub.status.idle": "2025-04-22T16:11:54.479922Z",
     "shell.execute_reply": "2025-04-22T16:11:54.479558Z",
     "shell.execute_reply.started": "2025-04-22T16:11:54.450787Z"
    }
   },
   "source": [
    "How do we evaluate if results are good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe946d9-e0ee-4f37-ac38-777997220e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(np.sum(ugmm.phi,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12737a5-22e4-42f3-b35d-4080bdbc29cf",
   "metadata": {},
   "source": [
    "## 5.1 Cluster assignments posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb7ee15-06f1-4ae9-87e8-b3db6920a992",
   "metadata": {},
   "source": [
    "We can start by visualizing the posterior distributions on the cluster assignments, to see what samples are more **uncertain**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a0424d-a63e-4b59-bd41-f69953e4fb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_std = np.argsort(np.std(ugmm.phi,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c3b864-2a87-46bc-997e-7c92337cfd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 3\n",
    "fig, ax = plt.subplots(1,L,figsize=(10, 4), sharey=True)\n",
    "for i in range(L):\n",
    "    \n",
    "    sns.barplot(ugmm.phi[sorted_std[i]], ax=ax[i])\n",
    "\n",
    "    msg = f'i = {sorted_std[i]}\\nx = {X[sorted_std[i]]:.2f}'\n",
    "    ax[i].text(0.0,0.46,msg,fontsize=12)\n",
    "    ax[i].set_xlabel('k')\n",
    "    ax[i].set_ylabel('P(k)')\n",
    "    \n",
    "    # filename = get_filename(f\"GMMexample_it{it}\",lecture_id=lecture_id)\n",
    "    # savefig(plt,outfile = filename,outdir = outdir_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793d0cbe-8768-4030-8250-4dccc604c218",
   "metadata": {},
   "source": [
    "Higher uncertainty is placed on samples that fall at the intersection between clusters.  \n",
    "We can now see what are the samples with **lower uncertainity**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b0e7df-9b14-4f91-9a69-e02206ea204d",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 3\n",
    "fig, ax = plt.subplots(1,L,figsize=(10, 4), sharey=True)\n",
    "for i in range(L):\n",
    "    \n",
    "    sns.barplot(ugmm.phi[sorted_std[-i-1]], ax=ax[i])\n",
    "\n",
    "    msg = f'i = {sorted_std[-i-1]}\\nx = {X[sorted_std[-i-1]]:.2f}'\n",
    "    ax[i].text(-0.4,0.9,msg,fontsize=12)\n",
    "    ax[i].set_xlabel('k')\n",
    "    ax[i].set_ylabel('P(k)')\n",
    "    \n",
    "    # filename = get_filename(f\"GMMexample_it{it}\",lecture_id=lecture_id)\n",
    "    # savefig(plt,outfile = filename,outdir = outdir_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8f6c1b-2daf-4a1b-ae27-9146a7de7b1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T09:34:13.453474Z",
     "iopub.status.busy": "2025-04-23T09:34:13.452835Z",
     "iopub.status.idle": "2025-04-23T09:34:13.484105Z",
     "shell.execute_reply": "2025-04-23T09:34:13.483423Z",
     "shell.execute_reply.started": "2025-04-23T09:34:13.453436Z"
    }
   },
   "source": [
    "Lower uncertainty is placed on samples that fall far from the intersection between clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab1af03-bfa4-4a37-8cde-4bf7c33e1b87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T09:37:04.130256Z",
     "iopub.status.busy": "2025-04-23T09:37:04.129642Z",
     "iopub.status.idle": "2025-04-23T09:37:04.161779Z",
     "shell.execute_reply": "2025-04-23T09:37:04.161177Z",
     "shell.execute_reply.started": "2025-04-23T09:37:04.130212Z"
    }
   },
   "source": [
    "## 5.2 Gaussian centers posteriors\n",
    "\n",
    "We can also check the posteriors of the gaussian means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2ee0e4-1c19-4b5d-8e5b-d173e211d692",
   "metadata": {},
   "outputs": [],
   "source": [
    "ugmm.phi.shape, c_GT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0963a9-f649-46ee-a787-ccd68fc38da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.array([0,2,1]) \n",
    "# P0 = tl.CalculatePermuation(ugmm.phi,c_GT) # permutation to match cluster by cluster\n",
    "# P = np.argmax(P0,axis=0) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dfe287-6d54-42f0-bc96-b89f74bc2774",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = ugmm.m.shape[0]\n",
    "\n",
    "fig, ax = plt.subplots(1,L,figsize=(10, 4), sharey=True)\n",
    "for i in range(L):\n",
    "    \n",
    "    sns.histplot(prng.normal(ugmm.m[P[i]], np.sqrt(ugmm.s2[P[i]]), SAMPLE),color=colors[P[i]], kde=True,line_kws={'ls':'--'},alpha=0.1, ax=ax[i])\n",
    "    ax[i].axvline(x=ugmm.m[P[i]],color=colors[P[i]],ls='--',label='Estimated')\n",
    "    ax[i].axvline(x=mu_arr[i],color='black',ls='-.',alpha=0.5,label='GT')\n",
    "    xlim = ax[i].get_xlim()\n",
    "    msg = f'k = {i}\\nx_GT = {mu_arr[i]:.2f}\\nx_est = {ugmm.m[P[i]]:.2f}'\n",
    "    ax[i].text(xlim[0],100,msg,fontsize=12)\n",
    "    ax[i].set_xlabel(r'$\\mu_k$')\n",
    "    # ax[i].set_ylabel('P(k)')\n",
    "plt.legend(loc='best')\n",
    "    \n",
    "    # filename = get_filename(f\"GMMexample_it{it}\",lecture_id=lecture_id)\n",
    "    # savefig(plt,outfile = filename,outdir = outdir_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b369b91a-767e-4e0d-9cee-f9bc9a79c0cf",
   "metadata": {},
   "source": [
    "## 5.3 Evaluation metrics\n",
    "We can for instance measure prediction quality in reconstructing the cluster assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34307765-efcf-4831-bd89-5dd6ecf84533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a11e3ab-e940-4c1f-a835-8d47a37c48e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(c_GT,ugmm.phi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ea7f88-f9b8-4e9f-8366-650f8ddf4582",
   "metadata": {},
   "source": [
    "We need a **baseline** for comparison, as this bare number is not interpretable (is it good? bad? ). \n",
    "\n",
    "For instance, we can build a random **permutation** of the ground truth. The worse performance is expected when we permute the whole ground truth cluster assignment vector.  \n",
    "Best performance is when we do not permute anything (GT is not manipulated).\n",
    "\n",
    "We can vary the proportion of manipulated GT entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083fc38a-3690-42e0-bfbe-99c0609d2853",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = c_GT.shape[0]\n",
    "perm = prng.permutation(np.arange(n_samples))\n",
    "\n",
    "print('rho','logL')\n",
    "for rho in np.linspace(0,1,21):\n",
    "    # rho = 0.9 # permuted %\n",
    "    n_perm = int(rho * n_samples)\n",
    "    \n",
    "    c_GT_perm = np.copy(c_GT)\n",
    "    c_GT_perm[perm[:n_perm]] = np.zeros((n_perm,K))\n",
    "    assert np.sum(np.sum(c_GT_perm,axis=1) == 0) == n_perm\n",
    "    c_GT_perm[perm[:n_perm], prng.choice(np.arange(K), n_perm)] = 1 \n",
    "    \n",
    "    assert np.all(np.sum(c_GT_perm,axis=1)==1)\n",
    "\n",
    "    print(f\"{rho:.2f} {log_loss(c_GT,c_GT_perm):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a69834a-08dc-4e06-a1cd-35495bc58704",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T10:11:53.619040Z",
     "iopub.status.busy": "2025-04-23T10:11:53.617417Z",
     "iopub.status.idle": "2025-04-23T10:11:53.654066Z",
     "shell.execute_reply": "2025-04-23T10:11:53.653605Z",
     "shell.execute_reply.started": "2025-04-23T10:11:53.618919Z"
    }
   },
   "source": [
    "Alternatively, we can check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a760d3-f2db-49b4-ae73-ca9edc05d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb5ce00-ca8b-457b-81a1-27b85faca461",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(np.argmax(c_GT,axis=1), np.argmax(ugmm.phi,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73eca3da-7276-46f7-817c-7ef2f063d14a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T10:13:51.052177Z",
     "iopub.status.busy": "2025-04-23T10:13:51.051342Z",
     "iopub.status.idle": "2025-04-23T10:13:51.081342Z",
     "shell.execute_reply": "2025-04-23T10:13:51.080789Z",
     "shell.execute_reply.started": "2025-04-23T10:13:51.052112Z"
    }
   },
   "source": [
    "Don't forget to permute!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ae5cc6-f16e-4b9f-bf91-81603c6fba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(np.argmax(c_GT,axis=1), P[np.argmax(ugmm.phi,axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5536687d-73c7-475c-b591-d68a30fcf9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = c_GT.shape[0]\n",
    "perm = prng.permutation(np.arange(n_samples))\n",
    "\n",
    "print('rho','logL')\n",
    "for rho in np.linspace(0,1,21):\n",
    "    # rho = 0.9 # permuted %\n",
    "    n_perm = int(rho * n_samples)\n",
    "    \n",
    "    c_GT_perm = np.copy(c_GT)\n",
    "    c_GT_perm[perm[:n_perm]] = np.zeros((n_perm,K))\n",
    "    assert np.sum(np.sum(c_GT_perm,axis=1) == 0) == n_perm\n",
    "    c_GT_perm[perm[:n_perm], prng.choice(np.arange(K), n_perm)] = 1 \n",
    "    \n",
    "    assert np.all(np.sum(c_GT_perm,axis=1)==1)\n",
    "\n",
    "    print(f\"{rho:.2f} {accuracy_score(np.argmax(c_GT,axis=1), np.argmax(c_GT_perm,axis=1)):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77def732-3028-45e2-9ac7-fadb0c0186b6",
   "metadata": {},
   "source": [
    "# 6. Appendix: 2D example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d918a61f-7396-4ff7-9a55-29917d9bfb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import BayesianGaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c1e471-3343-4924-b21e-025ec8fbd1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "prng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18ee765-5cda-450b-9ac6-8ed5177bfe06",
   "metadata": {},
   "source": [
    "## 6.1 Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4575bb8a-7ced-4ea9-aca1-cf60583ab163",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 500\n",
    "n_components = 3\n",
    "covars = np.array(\n",
    "    [[[0.7, 0.2], [0.2, 0.1]], [[0.5, 0.0], [0.0, 0.1]], [[0.5, 0.0], [0.0, 0.1]]]\n",
    ")\n",
    "samples = np.array([n_samples, n_samples, n_samples])\n",
    "means = np.array([[0.0, -0.70], [0.0, 0.0], [0.0, 0.70]])\n",
    "c_GT = np.hstack([np.zeros(n_samples), np.ones(n_samples), 2 * np.ones(n_samples)]).astype(int)\n",
    "\n",
    "\n",
    "c_GT_vect = np.zeros((n_components * n_samples,n_components))\n",
    "c_GT_vect[np.arange(n_samples),0]=1\n",
    "c_GT_vect[np.arange(n_samples,n_samples*2),1]=1\n",
    "c_GT_vect[np.arange(n_samples*2,n_samples*3),2]=1\n",
    "assert np.all(np.sum(c_GT_vect,axis=1)==1)\n",
    "\n",
    "c_GT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad54ce5-4f33-4d8a-88da-dca2fa0fccf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(\n",
    "    [\n",
    "        prng.multivariate_normal(means[j], covars[j], samples[j])\n",
    "        for j in range(n_components)\n",
    "    ]\n",
    ")\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9402730-a223-4fef-8429-ff4acf1ea448",
   "metadata": {},
   "source": [
    "## 6.2 Fit VI-GMM to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfc9163-db4e-413f-bfe1-0a012e2172a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = BayesianGaussianMixture(\n",
    "            covariance_type = 'diag',\n",
    "            weight_concentration_prior_type=\"dirichlet_distribution\",\n",
    "            n_components=1 * n_components,\n",
    "            reg_covar=0,\n",
    "            init_params=\"random\",\n",
    "            max_iter=1500,\n",
    "            mean_precision_prior=0.8,\n",
    "            random_state=seed,\n",
    "        )\n",
    "\n",
    "estimator.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70856348-9f96-4fe8-a2b3-8396d7f0e867",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.means_.shape, estimator.covariances_.shape, estimator.weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a2df41-5c2a-4682-abd6-3171ca6d615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimator.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90993efb-8b21-4cf2-8cd0-819e65ab03d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def multivariate_gaussian(pos, mu, Sigma):\n",
    "    \"\"\"Return the multivariate Gaussian distribution on array pos.\"\"\"\n",
    "\n",
    "    n = mu.shape[0]\n",
    "    Sigma_det = np.linalg.det(Sigma)\n",
    "    Sigma_inv = np.linalg.inv(Sigma)\n",
    "    N = np.sqrt((2*np.pi)**n * Sigma_det)\n",
    "    # This einsum call calculates (x-mu)T.Sigma-1.(x-mu) in a vectorized\n",
    "    # way across all the input variables.\n",
    "    fac = np.einsum('...k,kl,...l->...', pos-mu, Sigma_inv, pos-mu)\n",
    "\n",
    "    return np.exp(-fac / 2) / N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c8fa14-feb1-410d-8e38-254280ddbaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "N =  n_components * n_samples\n",
    "Xs = np.linspace(-2, 2, N)\n",
    "Ys = np.linspace(-2, 2, N)\n",
    "Xs, Ys = np.meshgrid(Xs, Ys)\n",
    "\n",
    "# Pack X and Y into a single 3-dimensional array\n",
    "pos = np.empty(Xs.shape + (2,))\n",
    "pos[:, :, 0] = Xs\n",
    "pos[:, :, 1] = Ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59339bdf-d6b5-4dc9-909e-8387af53006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "P = tl.CalculatePermuation(c_GT_vect,estimator.predict_proba(X))\n",
    "print(P.shape)\n",
    "P = np.argmax(P,axis=1)\n",
    "# P = np.array([1,2,0])\n",
    "P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772ca2da-17c8-404a-bc71-d6cf647f5a0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-23T12:28:02.642939Z",
     "iopub.status.busy": "2025-04-23T12:28:02.641983Z",
     "iopub.status.idle": "2025-04-23T12:28:02.674923Z",
     "shell.execute_reply": "2025-04-23T12:28:02.673915Z",
     "shell.execute_reply.started": "2025-04-23T12:28:02.642861Z"
    }
   },
   "source": [
    "We have inferred a diagonal covariance, need to transform in 2 X 2 matrix each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d623e2e3-d9e7-4eca-a195-73d255f626ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if estimator.covariances_.ndim != covars.ndim:\n",
    "    K = means.shape[0]\n",
    "    estimated_cov = np.zeros_like(covars)\n",
    "    for k in range(K):\n",
    "        np.fill_diagonal(estimated_cov[k], estimator.covariances_[k])\n",
    "else:\n",
    "    estimated_cov = np.copy(estimator.covariances_)\n",
    "estimated_cov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614cbdeb-805e-4eea-9ecc-6456ff7f07db",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.means_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2270d2d-eb4f-4342-8d86-6095ec957901",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,means.shape[0],figsize=(12,4),sharex=True,sharey=True)\n",
    "Z_gt = np.zeros(pos.shape[:2])\n",
    "for k in np.arange(means.shape[0]):\n",
    "    selected = c_GT == k\n",
    "    Z_gt = multivariate_gaussian(pos, means[k], covars[k])\n",
    "    Z_est = multivariate_gaussian(pos, estimator.means_[P[k]], estimated_cov[P[k]])\n",
    "    \n",
    "    ax[k].contour(Xs,Ys,Z_est,cmap='Reds',alpha=0.8,label='Estimated')\n",
    "    ax[k].contourf(Xs,Ys,Z_gt,cmap='Reds',label='GT')\n",
    "    ax[k].scatter(X[selected,0],X[selected,1],zorder=1,color=colors[k],alpha=0.5,s=10,label='Data')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d9492c-bf8f-414b-aafd-ff0751ecbe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(4,4))\n",
    "Z_gt = np.zeros(pos.shape[:2])\n",
    "k = 0\n",
    "selected = c_GT == k\n",
    "Z_gt = multivariate_gaussian(pos, means[k], covars[k])\n",
    "Z_est = multivariate_gaussian(pos, estimator.means_[P[k]],   estimated_cov[P[k]])\n",
    "# Z_est = multivariate_gaussian(pos, estimator.means_[P[k]] + np.array([-0.5,-0.2]), 3 * estimated_cov[P[k]])\n",
    "\n",
    "\n",
    "ax.contour(Xs,Ys,Z_est,cmap='Reds',alpha=0.8,label='Estimated')\n",
    "ax.contourf(Xs,Ys,Z_gt,cmap='Reds',label='GT')\n",
    "ax.scatter(X[selected,0],X[selected,1],zorder=1,color=colors[k],alpha=0.5,s=10,label='Data')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "filename = tl.get_filename(f\"GMMexample_2D_inf\",lecture_id=lecture_id)\n",
    "filename=None\n",
    "tl.savefig(plt,outfile = filename,outdir = outdir_fig)\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(4,4))\n",
    "Z_gt = np.zeros(pos.shape[:2])\n",
    "k = 0\n",
    "selected = c_GT == k\n",
    "Z_gt = multivariate_gaussian(pos, means[k], covars[k])\n",
    "Z_est = multivariate_gaussian(pos, estimator.means_[P[1]],   estimated_cov[P[1]])\n",
    "# Z_est = multivariate_gaussian(pos, estimator.means_[P[k]] + np.array([-0.5,-0.2]), 3 * estimated_cov[P[k]])\n",
    "\n",
    "\n",
    "ax.contour(Xs,Ys,Z_est,cmap='Reds',alpha=0.8,label='Estimated')\n",
    "ax.contourf(Xs,Ys,Z_gt,cmap='Reds',label='GT')\n",
    "ax.scatter(X[selected,0],X[selected,1],zorder=1,color=colors[k],alpha=0.5,s=10,label='Data')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "filename = tl.get_filename(f\"GMMexample_2D_inf1\",lecture_id=lecture_id)\n",
    "filename=None\n",
    "tl.savefig(plt,outfile = filename,outdir = outdir_fig)\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(4,4))\n",
    "Z_gt = np.zeros(pos.shape[:2])\n",
    "k = 0\n",
    "selected = c_GT == k\n",
    "Z_gt = multivariate_gaussian(pos, means[k], covars[k])\n",
    "Z_est = multivariate_gaussian(pos, estimator.means_[P[k]] + np.array([-0.5,-0.2]), 3 * estimated_cov[P[k]])\n",
    "\n",
    "\n",
    "ax.contour(Xs,Ys,Z_est,cmap='Reds',alpha=0.8,label='Estimated')\n",
    "ax.contourf(Xs,Ys,Z_gt,cmap='Reds',label='GT')\n",
    "ax.scatter(X[selected,0],X[selected,1],zorder=1,color=colors[k],alpha=0.5,s=10,label='Data')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "filename = tl.get_filename(f\"GMMexample_2D_inf2\",lecture_id=lecture_id)\n",
    "filename=None\n",
    "tl.savefig(plt,outfile = filename,outdir = outdir_fig)\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(4,4))\n",
    "Z_gt = np.zeros(pos.shape[:2])\n",
    "k = 0\n",
    "selected = c_GT == k\n",
    "Z_gt = multivariate_gaussian(pos, means[k], covars[k])\n",
    "Z_est = multivariate_gaussian(pos, estimator.means_[P[k]] + np.array([-0.5,-0.2]), 0.5 * estimated_cov[P[k]])\n",
    "\n",
    "\n",
    "ax.contour(Xs,Ys,Z_est,cmap='Reds',alpha=0.8,label='Estimated')\n",
    "ax.contourf(Xs,Ys,Z_gt,cmap='Reds',label='GT')\n",
    "ax.scatter(X[selected,0],X[selected,1],zorder=1,color=colors[k],alpha=0.5,s=10,label='Data')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "filename = tl.get_filename(f\"GMMexample_2D_inf3\",lecture_id=lecture_id)\n",
    "filename=None\n",
    "tl.savefig(plt,outfile = filename,outdir = outdir_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f1f0d9-8f74-4f25-9908-a1994872267b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a342085c-92c4-4959-bbd9-3d99949a3c82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
