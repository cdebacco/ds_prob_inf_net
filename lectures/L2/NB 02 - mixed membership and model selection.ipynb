{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "829a333c-75cf-48c2-88a5-0ecbefacc509",
   "metadata": {},
   "source": [
    "# L2: stochastic block model and community detection\n",
    "\n",
    "Here we explore 3 particular topics:\n",
    "- mixed-membership\n",
    "- model selection\n",
    "- adding node attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111bcd99-22e9-4b7c-88f8-fe3219a7fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bf21c4-bca0-421f-8c44-2e565c3c3590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f2f442-f113-4735-bf94-b05d91feec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../src/')\n",
    "import tools as tl\n",
    "import plot as viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f7d6bc-ed75-4214-a153-b0f5580dbddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "colormap = plt.cm.tab20\n",
    "colors = {i: colormap(i) for i in range(20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e5f6b2-9409-48df-8b88-2690944a7170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probinet.input.loader import build_adjacency_from_file\n",
    "from probinet.input.stats import print_graph_stats\n",
    "from probinet.models.mtcov import MTCOV\n",
    "# from probinet.visualization.plot import extract_bridge_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf121a3-9596-4103-b8bc-603928245c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir_fig = '../figures/'\n",
    "lecture_id = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ca535-63c6-4f14-96be-516d2d4c01f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "prng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35c50f1-c6d1-46b7-8d74-fa5506cd0184",
   "metadata": {},
   "source": [
    "# 1. Trade network\n",
    "Let's consider the trade network of the previous lecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1226c2-2ab9-4ab3-9137-347688b9c4ee",
   "metadata": {},
   "source": [
    "## 1.1 Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2f77f5-9609-406e-a282-0727c45944d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "indir = '../../../data/outdir/wto/'\n",
    "filename = 'wto_aob.csv'\n",
    "infile = f\"{indir}{filename}\"\n",
    "df = pd.read_csv(infile)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309da8af-846c-468a-8adc-478fb9f118c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'reporter_name'\n",
    "target = 'partner_name'\n",
    "weight = 'weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34765da-0690-41bc-998d-f74058a4716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "undirected = True\n",
    "force_dense = True\n",
    "binary = True\n",
    "data = build_adjacency_from_file(\n",
    "    f\"{indir}{filename}\",\n",
    "    ego=source,\n",
    "    alter=target,\n",
    "    sep=\",\",\n",
    "    undirected=undirected,\n",
    "    force_dense=force_dense,\n",
    "    binary=binary,\n",
    "    header=0,\n",
    ")\n",
    "# Print the names of the coordinates in the namedtuple gdata\n",
    "print(data._fields)\n",
    "\n",
    "nodeLabel2Id = {k:i for i,k in enumerate(data.nodes)}\n",
    "nodeId2Label = {i:k for i,k in enumerate(data.nodes)}\n",
    "\n",
    "Y = data.adjacency_tensor\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "\n",
    "nmax = 500\n",
    "node_order = np.argsort(-Y[0].sum(axis=1))\n",
    "viz.plot_matrix(Y,node_order=node_order[:nmax],title=f\"Y\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc3da8e-c239-4576-beae-ba2f1ce4c13b",
   "metadata": {},
   "source": [
    "Setup variables for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f0fd72-6a4a-49ba-9203-bc51776c900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = 10\n",
    "# node_size = [np.log(graph.degree[i]) * ms + 100 for i in data.nodes]\n",
    "# position = nx.spring_layout(data.graph_list[0], iterations=100, seed = seed)\n",
    "\n",
    "node_size = [np.log(data.graph_list[0].degree[i]) * ms + 20 for i in data.nodes]\n",
    "position = tl.get_custom_node_positions(data.graph_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415e0fa3-0965-4179-b0ac-eb0b9cdf85cd",
   "metadata": {},
   "source": [
    "## 1.2 Run a mixed-membership model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4332c12-da6f-4569-88d9-b6f0b09b6a18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T12:36:25.274525Z",
     "iopub.status.busy": "2025-04-11T12:36:25.272912Z",
     "iopub.status.idle": "2025-04-11T12:36:25.339943Z",
     "shell.execute_reply": "2025-04-11T12:36:25.339242Z",
     "shell.execute_reply.started": "2025-04-11T12:36:25.274445Z"
    }
   },
   "source": [
    "We use [`MTCOV`](https://doi.org/10.1038/s41598-020-72626-y), contained in `probinet`. This can also take in input node attributes, but we ignore this for the moment.\n",
    "\n",
    "   - Contisciani M., Power E.A. and De Bacco C. _Community detection with node attributes in multilayer networks_. Scientific reports, 10(1):15736, 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd96ce76-c791-4748-83a1-9b40c8c27d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = {} # to store the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101076dd-0f02-4301-b326-808a5a9e1ef4",
   "metadata": {},
   "source": [
    "### 1.2.1 Run another algorithm to use it as a bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8534820-a1d7-4a53-a57e-f7a5a461819d",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = 'louvain'\n",
    "\n",
    "G = nx.from_numpy_array(data.adjacency_tensor[0],edge_attr=weight)\n",
    "G.number_of_nodes(), G.number_of_edges()\n",
    "\n",
    "seed = 10\n",
    "resolution = 1.2 # the higher, the more and smaller the communities\n",
    "louvain = nx.community.louvain_communities(G, seed=seed,weight=weight,resolution=resolution)\n",
    "\n",
    "u[algo] = tl.from_louvain_to_u(louvain)\n",
    "print(u[algo].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a348f0e-d9d3-4e9f-b002-889791b1c8dd",
   "metadata": {},
   "source": [
    "### 1.2.2 Run MTCOV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2d8e72-2a94-45ab-88d4-91733674d69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    \"assortative\": True,\n",
    "    \"end_file\": \"_mtcov\",\n",
    "    \"out_folder\": '../../../data/outdir/wto/',\n",
    "    \"out_inference\": True,\n",
    "    \"undirected\": True,\n",
    "    \"rseed\": 10\n",
    "}\n",
    "num_realizations = 20\n",
    "plot_loglik = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4e24b0-cbd6-4689-aeb8-0d4c8aa25529",
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = [0.0,0.3,0.5,0.7,0.9, 0.99] # possible values for hyper-parameter `gamma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64adaf1c-0237-4f09-a82b-db9c7497b843",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MTCOV(num_realizations=num_realizations, plot_loglik=plot_loglik)\n",
    "\n",
    "X = np.copy(u['louvain']) # we can choose what dummy covariate to give in input. Here we use the result of another algorithm, pick the one you like most\n",
    "# X = np.zeros((len(data.nodes), 4)) # uncomment this if you want to give dummy data\n",
    "data = data._replace(design_matrix=X)\n",
    "\n",
    "K = 6\n",
    "params = {}\n",
    "for gamma in gammas:\n",
    "    params[gamma] = model.fit(data, K=K, gamma=gamma, rng=np.random.default_rng(config_dict[\"rseed\"]), **config_dict)\n",
    "\n",
    "    algo = f'mtcov_{gamma}'\n",
    "    u[algo] = params[gamma][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7c9d5b-999e-40de-978d-9a2c262cd248",
   "metadata": {},
   "source": [
    "## 1.3 Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba73090-c3f1-4544-bc1a-6b68b1781b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "u.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141cda5f-596a-4779-a356-0546a4d26984",
   "metadata": {},
   "source": [
    "### 1.3.1 Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaaaf59-30b8-445c-8a19-db3b6b363800",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = 'mtcov_0.0'\n",
    "\n",
    "plot_labels = False\n",
    "filename0 = f'WTO_network_{algo}_{plot_labels}'\n",
    "\n",
    "node_labels = {}\n",
    "for n,d in list(data.graph_list[0].degree()):\n",
    "    if d > 4: node_labels[n] = n\n",
    "    if np.count_nonzero(u[algo][nodeLabel2Id[n]]) > 1:\n",
    "        node_labels[n] = n\n",
    "        \n",
    "plt.figure(figsize=(16,10))\n",
    "\n",
    "nx.draw_networkx_labels(data.graph_list[0],position, font_size=8, alpha=0.8, labels=node_labels)\n",
    "nx.draw_networkx_edges(data.graph_list[0],pos=position,width=0.1)\n",
    "# plt.title(algo)\n",
    "plt.axis('off')\n",
    "\n",
    "if algo.startswith('mtcov'):\n",
    "    ax = plt.gca()\n",
    "    for j, n in enumerate(data.graph_list[0].nodes()):\n",
    "        wedge_sizes, wedge_colors = viz.extract_bridge_properties(j, colors, u[algo])\n",
    "        if len(wedge_sizes) > 0:\n",
    "            _ = plt.pie(\n",
    "                wedge_sizes,\n",
    "                center=position[n],\n",
    "                colors=wedge_colors,\n",
    "                radius=(node_size[j]) * 0.001\n",
    "            )\n",
    "            ax.axis(\"equal\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "filename = tl.get_filename(filename0,lecture_id=lecture_id)\n",
    "outdir = \"../figures/\"\n",
    "tl.savefig(plt,outfile = filename,outdir = outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c195d414-8aaf-4a38-a5a8-46284d9d6a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labels = {}\n",
    "for n,d in list(data.graph_list[0].degree()):\n",
    "    if d > 4: node_labels[n] = n\n",
    "        \n",
    "plt.figure(figsize=(16,10))\n",
    "L = len(u.keys())\n",
    "n_cols = 2\n",
    "n_rows = int(np.ceil(L / n_cols))\n",
    "\n",
    "for i, p in enumerate(u.keys()):\n",
    "    plt.subplot(n_rows,n_cols,i+1)\n",
    "    nx.draw_networkx_nodes(data.graph_list[0],position, node_size=node_size, node_color=tl.get_node_colors(colors, u[p]))\n",
    "    nx.draw_networkx_labels(data.graph_list[0],position, font_size=8, alpha=0.8, labels=node_labels)\n",
    "    nx.draw_networkx_edges(data.graph_list[0],pos=position,width=0.1)\n",
    "    plt.title(p)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1225a683-4118-4b5b-b64b-05f4541e64d7",
   "metadata": {},
   "source": [
    "### 1.3.2 Adjacency matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6397489e-f24d-4a80-9133-0185ab86ab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1, len(u.keys()),figsize=(18,6))\n",
    "\n",
    "for i,algo in enumerate(u.keys()):\n",
    "    node_order = tl.extract_node_order(u[algo])\n",
    "    viz.plot_matrix(Y,node_order=node_order,ax=axarr[i],title=f\"{algo}\",vmax = 1e-3,vmin=0)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77d2153-7ba4-43d7-847d-24b117e3290e",
   "metadata": {},
   "source": [
    "### 1.3.3. Focus on a specific partition and zoom in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7394d53b-fc5a-48e7-b5b6-3f6f96f4061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeLabel2size = {i:np.log(data.graph_list[0].degree[i]) * ms +300 for i in list(data.graph_list[0].nodes())}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a72cf8-7447-4d99-a4a9-47d5e83482ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-11T13:50:53.850647Z",
     "iopub.status.busy": "2025-04-11T13:50:53.849875Z",
     "iopub.status.idle": "2025-04-11T13:50:53.887580Z",
     "shell.execute_reply": "2025-04-11T13:50:53.886881Z",
     "shell.execute_reply.started": "2025-04-11T13:50:53.850597Z"
    }
   },
   "source": [
    "Play with the algorithm and check:\n",
    "- What are the **mixed-memership** nodes in the various results?\n",
    "- How do they change with algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1e868b-47f6-42d0-b376-fa07292938ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "u.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4589d95-c23f-4044-9373-d989f441d687",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = 'mtcov_0.5'\n",
    "communities = np.argmax(u[algo],axis=1)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14,8))\n",
    "K = u[algo].shape[-1]\n",
    "n_cols = 3\n",
    "n_rows = int(np.ceil(K / n_cols))\n",
    "for i, k in enumerate(np.arange(u[algo].shape[-1])):\n",
    "    community = np.where(communities==k)[0]\n",
    "    H = data.graph_list[0].subgraph([nodeId2Label[n] for n in community])\n",
    "    c = colors[i]\n",
    "    # p = nx.spring_layout(H, iterations=100,k=0.1)\n",
    "    p = nx.circular_layout(H)\n",
    "    ns = [nodeLabel2size[n] for n in H.nodes()]\n",
    "    plt.subplot(n_rows,n_cols,i+1)\n",
    "    nx.draw_networkx_edges(H,pos=p, width=0.1)\n",
    "    nx.draw_networkx_labels(H,pos=p, font_size=8, alpha=0.8)\n",
    "    if algo.startswith('mtcov'):\n",
    "        ax = plt.gca()\n",
    "        for j, n in enumerate(H.nodes()):\n",
    "            wedge_sizes, wedge_colors = viz.extract_bridge_properties(j, colors, u[algo][communities==k])\n",
    "            if len(wedge_sizes) > 0:\n",
    "                _ = plt.pie(\n",
    "                    wedge_sizes,\n",
    "                    center=p[n],\n",
    "                    colors=wedge_colors,\n",
    "                    radius=(ns[j]) * 0.0003\n",
    "                )\n",
    "                ax.axis(\"equal\")\n",
    "    else:\n",
    "        nx.draw_networkx_nodes(H,pos=p, node_size=ns, node_color=c)\n",
    "        \n",
    "    \n",
    "    plt.title(k)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b7bb75-8fb0-48d3-a995-6613f5ce5848",
   "metadata": {},
   "source": [
    "## 2. Model selection\n",
    "\n",
    "What is the best among these results?  \n",
    "To find out, we need to run a **model selection** criteria.  \n",
    "Here we focus on **cross-validation** (CV). For this, we need to:\n",
    "1. **hide** part of the dataset, splitting into train and test sets.\n",
    "2. **learn** model parameters by fitting on the **training** set\n",
    "3. **measure performance** metric on the **test** set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc6270c-0cff-423c-bee4-7ffea63bef8f",
   "metadata": {},
   "source": [
    "### 2.1 Hide part of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274601fa-5a6d-424a-8e3a-25fbab1b5afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_indices_symmetric(shape, seed: int = 10):\n",
    "    '''\n",
    "    To extract a symmetric mask containing (A_ij,A_ji)\n",
    "    '''\n",
    "    L = shape[0]\n",
    "    N = shape[-1]\n",
    "    n_samples = int(N * (N-1) * 0.5) # upper triangle excluding diagonal\n",
    "    indices = [np.arange(n_samples) for l in range(L)]\n",
    "    rng = np.random.RandomState(seed)\n",
    "    for l in range(L):rng.shuffle(indices[l])\n",
    "    return indices\n",
    "    \n",
    "def extract_mask_symmetric_kfold(indices, N, NFold: int = 5):\n",
    "    '''\n",
    "    Symmetric mask: contains pairs (i,j) and (j,i) --> for undirected networks\n",
    "    KFold : no train/test sets intersect across the K folds \n",
    "    '''\n",
    "    L = len(indices)\n",
    "    mask = {f:np.zeros((L,N,N),dtype=bool) for f in range(NFold)}\n",
    "    for fold in range(NFold):\n",
    "        for l in range(L):\n",
    "            n_samples = len(indices[l])\n",
    "            test = indices[l][fold * (n_samples // NFold):(fold + 1) * (n_samples // NFold)]\n",
    "            # train = list(set(indices).difference(set(test)))\n",
    "            mask0 = np.zeros((n_samples),dtype=bool)\n",
    "            mask0[test] = 1\n",
    "            mask[fold][l][np.triu_indices(N, k = 1)] = mask0\n",
    "            mask[fold][l] = mask[fold][l] + mask[fold][l].T \n",
    "    return mask\n",
    "    \n",
    "def extract_mask(shape, out_mask = False, outfolder: str = '../../../data/output/tests/cv/', outfile = None,\n",
    "                seed: int = 10, NFold: int = 5):\n",
    "\n",
    "    indices = shuffle_indices_symmetric(shape, seed=seed)\n",
    "    mask = extract_mask_symmetric_kfold(indices, shape[-1],NFold=NFold)\n",
    "   \n",
    "\n",
    "    if out_mask:  # output the masks into files\n",
    "        for fold in mask.keys():\n",
    "            outmask = outfolder + outfile + '_' + str(fold)\n",
    "            np.savez_compressed(outmask + '.npz', mask = np.where(mask[fold] > 0))\n",
    "            # To load: mask = np.load('mask_f0.npz'), e.g. print(np.array_equal(maskG, mask['maskG']))\n",
    "            print('Masks saved in:', outmask)\n",
    "\n",
    "    return mask\n",
    "\n",
    "def extract_train_test_sparse(Y, maskG, fold: int = 0):\n",
    "\n",
    "    L = Y.shape[0]\n",
    "    N = Y.shape[-1]\n",
    "    subs_test = (Y.subs[0][maskG[fold]], Y.subs[1][maskG[fold]], Y.subs[2][maskG[fold]])\n",
    "    vals_test = Y.vals[maskG[fold]]\n",
    "\n",
    "    if type(maskG[fold][0].item()) == int:\n",
    "        number_nnz = Y.subs[0].shape[0]\n",
    "        mask_train = np.array([i for i in np.arange(number_nnz) if i not in maskG[fold]])\n",
    "    elif type(maskG[fold][0].item()) == bool:\n",
    "        mask_train = np.logical_not(maskG[fold])\n",
    "    else:\n",
    "        raise ValueError(f\"Type of mask entries should be int or bool. It is {type(maskG[fold][0].item())}!\")\n",
    "    subs_train = (Y.subs[0][mask_train], Y.subs[1][mask_train], Y.subs[2][mask_train])\n",
    "    vals_train = Y.vals[mask_train]\n",
    "    # Y_train = skt.sptensor(subs_train, vals_train, shape=(L, self.N, self.N), dtype=vals_train.dtype)\n",
    "\n",
    "    return Y_train,Y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ae22f1-a050-4692-8e67-907bd4d5cfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "cv_mask = extract_mask(data.adjacency_tensor.shape, seed = seed, )\n",
    "cv_mask.keys(), cv_mask[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e22db3-6523-4b9b-81d1-0c5c6a55fd60",
   "metadata": {},
   "source": [
    "Check that we are correctly splitting the folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4984c93d-bb49-4aec-86c3-d36b2ef750e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in cv_mask.items():\n",
    "    assert np.allclose(np.where(v>0)[1].shape[0] ,  Y.shape[1] * (Y.shape[1] - 1) / 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42f784c-2bd8-4ffb-a9d1-c6a8186c253c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T15:17:48.715425Z",
     "iopub.status.busy": "2025-04-14T15:17:48.714462Z",
     "iopub.status.idle": "2025-04-14T15:17:48.741153Z",
     "shell.execute_reply": "2025-04-14T15:17:48.740656Z",
     "shell.execute_reply.started": "2025-04-14T15:17:48.715400Z"
    }
   },
   "source": [
    "Extract edges in the test set.  \n",
    "First, let's fix a `fold`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4380e0f6-afba-41a5-84ba-9bdb34df4729",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5c9b87-5f6f-4344-8cc8-1a0ff9c8e247",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeLabel2Id = {n:i for i,n in enumerate(data.nodes)}\n",
    "nodeId2Label = {i:n for i,n in enumerate(data.nodes)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84c62a2-1c50-489a-af2f-990b0477fdbb",
   "metadata": {},
   "source": [
    "Build test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b0a2ec-d2c3-40b8-a08b-2d2511578c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = np.where(cv_mask[fold] > 0)[1:]\n",
    "nodes1 = [nodeId2Label[i] for i in subs[0]]\n",
    "nodes2 = [nodeId2Label[i] for i in subs[1]]\n",
    "ws = data.adjacency_tensor[cv_mask[fold]].astype(int)\n",
    "\n",
    "df_test = pd.DataFrame({source: nodes1, target: nodes2, weight: ws})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43e9274-0b70-45b4-8dda-535fc230c8bd",
   "metadata": {},
   "source": [
    "Check that it makes sense (symmetry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85124c89-1452-4d78-ad39-7672ae695d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[df_test[weight]>0].head(n=10)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5e23c8-d8c3-4eff-805d-1fa63c737b45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T15:40:45.694844Z",
     "iopub.status.busy": "2025-04-14T15:40:45.694056Z",
     "iopub.status.idle": "2025-04-14T15:40:45.743348Z",
     "shell.execute_reply": "2025-04-14T15:40:45.742729Z",
     "shell.execute_reply.started": "2025-04-14T15:40:45.694801Z"
    }
   },
   "source": [
    "Build training dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5369bb-2507-4b57-8934-0ba9c4b26de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.merge(df_test[df_test[weight]>0], how='left', indicator=True).query('_merge == \"left_only\"').drop('_merge', axis=1)\n",
    "df_train = pd.concat([df_train, df_test[df_test[weight]==0]],axis=0)\n",
    "assert len(df) == len(df_train[df_train[weight]>0]) + len(df_test[df_test[weight]>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9b4ca3-fe9e-4157-97cb-4e0550eca403",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T15:40:54.861877Z",
     "iopub.status.busy": "2025-04-14T15:40:54.861291Z",
     "iopub.status.idle": "2025-04-14T15:40:54.895642Z",
     "shell.execute_reply": "2025-04-14T15:40:54.895011Z",
     "shell.execute_reply.started": "2025-04-14T15:40:54.861838Z"
    }
   },
   "source": [
    "Save into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2255b9-f3a7-4deb-9e98-8886854ee278",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = '../../../data/outdir/wto/cv/'\n",
    "filename = f'wto_aob_fold{fold}_train.csv'\n",
    "tl.save_df_to_file(df_train,filename =filename, outdir=outdir)\n",
    "filename = f'wto_aob_fold{fold}_test.csv'\n",
    "tl.save_df_to_file(df_test,filename =filename, outdir=outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a599e50-53ad-43ba-91d2-ec2ecbd219ed",
   "metadata": {},
   "source": [
    "### 2.2 Run inference on training \n",
    "We repeat the same pipeline we had before with the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7db225-2d5e-4187-b581-56f90c355899",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = '../../../data/outdir/wto/cv/'\n",
    "filename = f'wto_aob_fold{fold}_train.csv'\n",
    "\n",
    "undirected = True\n",
    "force_dense = True\n",
    "binary = True\n",
    "data_cv = build_adjacency_from_file(\n",
    "    f\"{outdir}{filename}\",\n",
    "    ego=source,\n",
    "    alter=target,\n",
    "    sep=\",\",\n",
    "    undirected=undirected,\n",
    "    force_dense=force_dense,\n",
    "    binary=binary,\n",
    "    header=0,\n",
    ")\n",
    "# Print the names of the coordinates in the namedtuple gdata\n",
    "print(data_cv._fields)\n",
    "\n",
    "Y_cv = data_cv.adjacency_tensor\n",
    "print(Y_cv.shape)\n",
    "plt.figure(figsize=(2,2))\n",
    "\n",
    "nmax = 500\n",
    "node_order = np.argsort(-Y_cv[0].sum(axis=1))\n",
    "viz.plot_matrix(Y_cv,node_order=node_order[:nmax],title=f\"Y\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65e411d-cf3e-4aba-8451-4e448ec86977",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = 10\n",
    "\n",
    "node_size_cv = [np.log(data_cv.graph_list[0].degree[i]) * ms + 20 for i in data_cv.nodes]\n",
    "position_cv = tl.get_custom_node_positions(data_cv.graph_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a915987-c5e2-4970-88e3-f33f6a7cecae",
   "metadata": {},
   "source": [
    "#### 2.2.1 First, let's learn with a deterministic algorithm (to use it as covariate for MTCOV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a22d3bc-bd36-4336-9eb0-3cb3636a3d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_cv = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958f4e0a-61ec-436d-8e2f-5156635f955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = 'louvain'\n",
    "\n",
    "G = nx.from_numpy_array(data_cv.adjacency_tensor[0],edge_attr=weight)\n",
    "G.number_of_nodes(), G.number_of_edges()\n",
    "\n",
    "seed = 10\n",
    "resolution = 1.2 # the higher, the more and smaller the communities\n",
    "louvain = nx.community.louvain_communities(G, seed=seed,weight=weight,resolution=resolution)\n",
    "\n",
    "u_cv[algo] = tl.from_louvain_to_u(louvain)\n",
    "print(u_cv[algo].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4706c43f-865a-49c6-80a7-42a47d2ae72e",
   "metadata": {},
   "source": [
    "#### 2.2.2 Run MTCOV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe43dc1d-bacb-4d4c-9b64-4bd3c13aaa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = [0.0,0.3,0.5,0.7,0.9,0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1400e2ab-c0a5-46a6-8435-35b45a73b186",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MTCOV(num_realizations=num_realizations, plot_loglik=plot_loglik)\n",
    "\n",
    "X = np.copy(u_cv['louvain']) # we can choose what dummy covariate to give in input. Here we use the result of another algorithm, pick the one you like most\n",
    "# X = np.zeros((len(data.nodes), 4)) # uncomment this if you want to give dummy data\n",
    "data_cv = data_cv._replace(design_matrix=X)\n",
    "\n",
    "K = 10\n",
    "params_cv = {}\n",
    "for gamma in gammas:\n",
    "    params_cv[gamma] = model.fit(data_cv, K=K, gamma=gamma, rng=np.random.default_rng(config_dict[\"rseed\"]), **config_dict)\n",
    "\n",
    "    algo = f'mtcov_{gamma}'\n",
    "    u_cv[algo] = params_cv[gamma][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b4400b-a945-484c-a88a-f0b64f8124ce",
   "metadata": {},
   "source": [
    "#### 2.3 Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81de3511-98dd-4a29-a868-7904774da086",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nodeLabel2Id_cv = {k:i for i,k in enumerate(data_cv.nodes)}\n",
    "nodeId2Label_cv = {i:k for i,k in enumerate(data_cv.nodes)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b06d26-af05-4e2c-a388-d79490dcc75f",
   "metadata": {},
   "source": [
    " Check if number of nodes are the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545dd0ed-e23d-42a3-a85b-48a0b4df1104",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(data_cv.nodes)==len(data.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40102aa-82c2-40c9-a2a6-1d5a4daae83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labels_cv = {}\n",
    "for n,d in list(data_cv.graph_list[0].degree()):\n",
    "    if d > 4: node_labels_cv[n] = n\n",
    "        \n",
    "plt.figure(figsize=(16,10))\n",
    "L = len(u_cv.keys())\n",
    "n_cols = 2\n",
    "n_rows = int(np.ceil(L / n_cols))\n",
    "\n",
    "for i, p in enumerate(u_cv.keys()):\n",
    "    plt.subplot(n_rows,n_cols,i+1)\n",
    "    nx.draw_networkx_nodes(data_cv.graph_list[0],position, node_size=node_size_cv, node_color=tl.get_node_colors(colors, u_cv[p]))\n",
    "    nx.draw_networkx_labels(data_cv.graph_list[0],position, font_size=8, alpha=0.8, labels=node_labels_cv)\n",
    "    nx.draw_networkx_edges(data_cv.graph_list[0],pos=position,width=0.1)\n",
    "    plt.title(p)\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eccd38-6660-4c7f-875f-202537b17890",
   "metadata": {},
   "source": [
    "#### What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4595149-cad6-4e65-bc64-c8a75eb721b7",
   "metadata": {},
   "source": [
    "#### Adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e6e80c-0d0c-4659-8f52-94b6c03ff7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1, len(u_cv.keys()),figsize=(18,6))\n",
    "\n",
    "for i,algo in enumerate(u_cv.keys()):\n",
    "    node_order = tl.extract_node_order(u_cv[algo])\n",
    "    viz.plot_matrix(Y_cv,node_order=node_order,ax=axarr[i],title=f\"{algo}\",vmax = 1e-3,vmin=0)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3072af0-1fcb-46de-8333-4df8ccf6561f",
   "metadata": {},
   "source": [
    "### 3. Measure performance metric on the test set\n",
    "We use AUC as metric and use `probinet` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961caa99-ddfd-48ec-abe9-1f2a3e81bc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from probinet.evaluation.link_prediction import compute_link_prediction_AUC\n",
    "from probinet.evaluation.expectation_computation import compute_mean_lambda0\n",
    "from probinet.evaluation.likelihood import loglikelihood_network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d2582c-87fb-492a-b0d8-2ab38432ddd8",
   "metadata": {},
   "source": [
    "#### 3.1 Compute the predicted adjacency tensor\n",
    "Each model has its own way to compute the predicted `Y`.  \n",
    "**Question**: what is the predicted Y of Louvain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb9452c-ea13-419e-a6a6-96bab0b1aacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = {algo: compute_mean_lambda0(v[0],v[1],v[2]) for algo, v in params_cv.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402478d4-65a1-4df2-bcdb-92df96c0568e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(2, len(params_cv.keys()),figsize=(18,6))\n",
    "\n",
    "for i,algo in enumerate(params_cv.keys()):\n",
    "    node_order = tl.extract_node_order(u_cv[f\"mtcov_{algo}\"])\n",
    "    viz.plot_matrix(Y_cv,node_order=node_order,ax=axarr[0,i],title=f\"True: {algo}\",vmax = 1e-3,vmin=0)\n",
    "    viz.plot_matrix(Y_pred[algo],node_order=node_order,ax=axarr[1,i],title=f\"Pred: {algo}\",vmin=0)\n",
    "\n",
    "    \n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74842885-fd95-4af4-9a92-3fdc31b4e508",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "auc = [np.round(compute_link_prediction_AUC(data.adjacency_tensor,y_pred, mask=np.logical_not(cv_mask[fold])),3) for a,y_pred in Y_pred.items()]\n",
    "df_auc = pd.DataFrame({'algo':[a for a in Y_pred.keys()],'auc':auc})\n",
    "df_auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f5a063-0622-4098-9cd5-028a3d78b5a2",
   "metadata": {},
   "source": [
    "#### What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c27d665-5e69-4da8-ac2c-bafc3d0e7478",
   "metadata": {},
   "source": [
    "#### 3.2 Use the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb6ce6b-3593-4377-90b1-6195aa9b6968",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = '../../../data/outdir/wto/cv/'\n",
    "filename = f'wto_aob_fold{fold}_test.csv'\n",
    "\n",
    "undirected = True\n",
    "force_dense = True\n",
    "binary = True\n",
    "data_test = build_adjacency_from_file(\n",
    "    f\"{outdir}{filename}\",\n",
    "    ego=source,\n",
    "    alter=target,\n",
    "    sep=\",\",\n",
    "    undirected=undirected,\n",
    "    force_dense=force_dense,\n",
    "    binary=binary,\n",
    "    header=0,\n",
    ")\n",
    "\n",
    "Y_test = data_test.adjacency_tensor\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "\n",
    "nmax = 500\n",
    "node_order = np.argsort(-Y_test[0].sum(axis=1))\n",
    "viz.plot_matrix(Y_test,node_order=node_order[:nmax],title=f\"Y test\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72838cf0-99ca-4034-8efc-e08b8731594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(data_test.nodes) ==  len(data_cv.nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd621a6-fe8e-45a5-a072-df6445afaa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert data_test.nodes == data_cv.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2944a8b-94f9-40b4-80f6-1667cd09d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "auc = [np.round(compute_link_prediction_AUC(data.adjacency_tensor,y_pred, mask=cv_mask[fold]),3) for a,y_pred in Y_pred.items()]\n",
    "df_auc_test = pd.DataFrame({'algo':[a for a in Y_pred.keys()],'auc_test':auc})\n",
    "df_auc = df_auc.merge(df_auc_test,on='algo')\n",
    "df_auc.rename(columns={'auc':'auc_train'},inplace=True)\n",
    "df_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f049f6-8524-40b0-92a3-77b2239cf97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(2, len(params_cv.keys()),figsize=(18,6))\n",
    "\n",
    "for i,algo in enumerate(params_cv.keys()):\n",
    "    node_order = tl.extract_node_order(u_cv[f\"mtcov_{algo}\"])\n",
    "    viz.plot_matrix(Y_test,node_order=node_order,ax=axarr[0,i],title=f\"True: {algo}\",vmax = 1e-3,vmin=0)\n",
    "    viz.plot_matrix(Y_pred[algo],node_order=node_order,ax=axarr[1,i],title=f\"Pred: {algo}\",vmin=0)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7955a30-cf1c-46fa-a19b-c612abdbd1f9",
   "metadata": {},
   "source": [
    "#### 3.3 Alternative prediction metrics\n",
    "\n",
    "Beside AUC, we can use other metrics. For instance:\n",
    "- heldout loglikelihood, the log-likelihood on the test set\n",
    "- binary cross-entropy or [log-loss](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.log_loss.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8777d2-4474-4472-8bf8-0a60773fc098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import factorial\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd13b5-1939-4d80-a734-c4185c9344e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loglikelihood(\n",
    "    B: np.ndarray,\n",
    "    u: np.ndarray,\n",
    "    v: np.ndarray,\n",
    "    w: np.ndarray,\n",
    "    mask: np.ndarray = None,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute the log-likelihood for the network structure.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    B : np.ndarray\n",
    "        Graph adjacency tensor.\n",
    "    u : np.ndarray\n",
    "        Membership matrix (out-degree).\n",
    "    v : np.ndarray\n",
    "        Membership matrix (in-degree).\n",
    "    w : np.ndarray\n",
    "        Affinity tensor.\n",
    "    mask : Optional[np.ndarray]\n",
    "        Mask for selecting a subset in the adjacency tensor.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Log-likelihood value for the network structure.\n",
    "    \"\"\"\n",
    "    if mask is None:\n",
    "        # Compute the expected adjacency tensor\n",
    "        M = compute_mean_lambda0(u,v,w)\n",
    "        logM = np.zeros(M.shape)\n",
    "        logM[M > 0] = np.log(M[M > 0])\n",
    "        return (B * logM).sum() - M.sum() -(np.log(factorial(B.astype(int)))).sum()\n",
    "\n",
    "    # Compute the expected adjacency tensor for the masked elements\n",
    "    lambda_poisson = compute_mean_lambda0(u,v,w)\n",
    "    M = lambda_poisson[mask > 0]\n",
    "    logM = np.zeros(M.shape)\n",
    "    logM[M > 0] = np.log(M[M > 0])\n",
    "    return (B[mask > 0] * logM).sum() - M.sum() - (np.log(factorial(B[mask > 0].astype(int)))).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedaaf54-7afe-4dc3-86b7-2e39810232b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logL_test = [np.round(get_loglikelihood(data.adjacency_tensor,v[0],v[1],v[2],mask = cv_mask[fold]),3) for a,v in params_cv.items()]\n",
    "logL_train = [np.round(get_loglikelihood(data.adjacency_tensor,v[0],v[1],v[2],mask = np.logical_not(cv_mask[fold])),3) for a,v in params_cv.items()]\n",
    "bce_test = [np.round(log_loss(data.adjacency_tensor[cv_mask[fold]],y_pred[cv_mask[fold]]),3) for a,y_pred in Y_pred.items()]\n",
    "bce_train = [np.round(log_loss(data.adjacency_tensor[np.logical_not(cv_mask[fold])],y_pred[np.logical_not(cv_mask[fold])]),3) for a,y_pred in Y_pred.items()]\n",
    "\n",
    "df_holl = pd.DataFrame({'algo':[a for a in params_cv.keys()],'logL_train':logL_train,'logL_test':logL_test,\n",
    "                        'bce_train':bce_train,'bce_test':bce_test\n",
    "                       })\n",
    "\n",
    "df_auc = df_auc.merge(df_holl,on='algo')\n",
    "# df_auc.rename(columns={'auc':'auc_train'},inplace=True)\n",
    "df_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c832dc21-9255-4c6f-84fa-bd8c97ad3909",
   "metadata": {},
   "source": [
    "#### How can we make results better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14231fda-612e-4cc0-ba23-99743cc30fdc",
   "metadata": {},
   "source": [
    "# 4. Adding node attributes\n",
    "We can add extra information (if available) and see if this makes results better.  \n",
    "For instance, we can use information about the country as what countries are in some agreement, e.g. are in OECD.  \n",
    "**Idea**: if this extra information is correlated with community structure, it can help the algorithm finding a better partition.  \n",
    "This should be particularly helpful in the presence of sparse data, where there is not much information to start with. \n",
    "\n",
    "Here we use the python library [`country_converter`](https://github.com/IndEcol/country_converter), which allows retrieving various country-level information easily. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bcf9d4-b5f3-4ea3-9a9e-35f4fbaf96cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import country_converter as coconv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febd9729-c07a-4747-b00a-31178b3aa2b1",
   "metadata": {},
   "source": [
    "## 4.1 Attribute processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ddbf79-de81-4434-acc7-2647b9c25209",
   "metadata": {},
   "source": [
    "First let's check some example grouping based on official agreements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12480ed-d39a-4e1b-a109-ee8cfddbf826",
   "metadata": {},
   "source": [
    "And extract the list of countries in a grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6f1f78-ffd1-4099-9962-d2737aa10fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = coconv.CountryConverter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdda4a9-55be-4818-93a1-53e0d057239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.valid_class#[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e14d0a-23e6-4937-a510-51c673a8001a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_group = 'OECD'\n",
    "# ref_group = 'EU28'\n",
    "assert ref_group in cc.valid_class, f\"{ref_group} not found in {cc.valid_class}!\"\n",
    "\n",
    "gt_groups = list(eval(f'cc.{ref_group}.name_short.unique()'))\n",
    "gt_groups.append('European Union')\n",
    "gt_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2e122c-24c3-4798-8f86-c05a16fc08ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T07:15:33.518811Z",
     "iopub.status.busy": "2025-04-16T07:15:33.518294Z",
     "iopub.status.idle": "2025-04-16T07:15:33.549358Z",
     "shell.execute_reply": "2025-04-16T07:15:33.548675Z",
     "shell.execute_reply.started": "2025-04-16T07:15:33.518765Z"
    }
   },
   "source": [
    "We need to convert the names in the dataframe to the same naming as in this extra information, using `name_short`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b5a841-df37-420c-a57a-112d8b6e182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_short = coconv.convert(names=data.nodes, to='name_short',not_found=None)\n",
    "nameRaw2Short = {data.nodes[i]: names_short[i] for i in range(len(names_short))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1f5517-cf4f-442d-975d-b30600d7c54a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T07:00:30.383130Z",
     "iopub.status.busy": "2025-04-16T07:00:30.383030Z",
     "iopub.status.idle": "2025-04-16T07:00:30.394600Z",
     "shell.execute_reply": "2025-04-16T07:00:30.394321Z",
     "shell.execute_reply.started": "2025-04-16T07:00:30.383122Z"
    }
   },
   "source": [
    "We are ready to build a **node attribute** stating what countries are in the reference agreement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c303ff6d-3438-42a1-a14b-27ef8ac8f42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 2 # if 2: binary\n",
    "X = np.zeros((len(data.nodes),C)).astype(int)\n",
    "# X = np.zeros((len(data.nodes), 4)) # uncomment this if you want to give dummy data\n",
    "data_cv = data_cv._replace(design_matrix=X)\n",
    "for i,n in enumerate(data.nodes):\n",
    "    if nameRaw2Short[n] in gt_groups:\n",
    "        X[i,0] = 1\n",
    "    else:\n",
    "        X[i,1] = 1\n",
    "        \n",
    "assert np.all(np.sum(X,axis=1) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b04ce6-2faf-479f-8f79-43f4b6d509bd",
   "metadata": {},
   "source": [
    "## 4.2 Run MTCOV with valid attribute\n",
    "\n",
    "This time we do a cycle over all folds and then take the mean. We use the utils functions inside `cv_tools.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30e28d7-4fdb-4fea-a3aa-86806c7b97a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv_tools as cvtl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96135cd-f106-4232-a2f1-9a4267e9615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = [0.0,0.3,0.5,0.7,0.9,0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced1bf2c-361f-4bbd-a90c-110b62fafbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loglik = False\n",
    "num_realizations = 20\n",
    "max_iter = 500\n",
    "decision = 1\n",
    "convergence_tol = 1e-3\n",
    "data = data._replace(design_matrix=X)\n",
    "\n",
    "model = MTCOV(num_realizations=num_realizations, plot_loglik=plot_loglik,max_iter=max_iter,decision=decision,convergence_tol=convergence_tol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4cfcea-9d19-4b98-9fe6-c97ee68081bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_cv =  { f: {} for f in cv_mask.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc33bf6-7599-4f9e-95a4-e96dd9624686",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_meta = np.copy(X)\n",
    "attrib_label = 'OECD'\n",
    "# X_meta = np.copy(X_UN)\n",
    "# attrib_label = 'UNRegion'\n",
    "\n",
    "K = 6\n",
    "for fold, mask in cv_mask.items():\n",
    "    for gamma in gammas:\n",
    "        data_cv = cvtl.get_df_train_test(df,data,cv_mask,fold=fold)\n",
    "        data_cv = data_cv._replace(design_matrix=X_meta)\n",
    "        params_cv[fold][gamma] = model.fit(data_cv, K=K, gamma=gamma, rng=np.random.default_rng(config_dict[\"rseed\"]), **config_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed5d484-35bb-4ee1-a098-995a2f85c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_cv.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573ecf07-8746-41cc-86b4-b461a1557ac1",
   "metadata": {},
   "source": [
    "## 4.3 Evaluate performance\n",
    "We follow the same steps as before. Now we use functions inside `cv_tools.py` to extract these quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5f83de-30f6-4dab-96ca-17cd8ee3a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.concat([cvtl.get_prediction_results(data, params_cv[fold], cv_mask,fold=fold) for fold in cv_mask.keys()])\n",
    "df_pred.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8b26a4-228a-473c-b75c-d2e599f38969",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_mean = df_pred.groupby(by='algo').agg('mean').drop(columns=['fold']).reset_index()\n",
    "df_pred_std = df_pred.groupby(by='algo').agg('std').drop(columns=['fold']).reset_index()\n",
    "\n",
    "metrics = ['auc_test', \t'logL_test', \t'bce_test']\n",
    "df_pred_mean.style.background_gradient(subset=metrics,cmap=plt.cm.RdYlGn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3183496-1d36-48c4-a858-72dff7b0a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255f38f4-9cf4-451a-a104-62c191b0e664",
   "metadata": {},
   "source": [
    "Colors are fine, but we can find a more intuitive visualization to highlight the best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bae9072-09ef-4440-8537-3288a593f771",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = viz.default_colors[6]\n",
    "L = len(metrics)\n",
    "\n",
    "xticks = np.arange(len(gammas))\n",
    "\n",
    "fig, axs = plt.subplots(1,L,figsize=(12,4),sharex=True)\n",
    "for i in range(L):\n",
    "    m = metrics[i]\n",
    "    axs[i].scatter(xticks,df_pred_mean[m],s=200,color=c, edgecolor='black')\n",
    "    axs[i].errorbar(xticks,df_pred_mean[m],yerr=df_pred_std[m], linewidth=1, capsize=4, capthick=1, color=c)\n",
    "    axs[i].set_xlabel('Model')\n",
    "    axs[i].set_ylabel(m)\n",
    "    axs[i].set_xticks(xticks,gammas)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# filename = tl.get_filename(f'wto_cv_example', lecture_id=lecture_id)\n",
    "filename = None\n",
    "tl.savefig(plt, outfile=filename, outdir=outdir_fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262d9b84-f7db-4f55-9fc1-c311d60f35de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T09:52:43.957176Z",
     "iopub.status.busy": "2025-04-16T09:52:43.956700Z",
     "iopub.status.idle": "2025-04-16T09:52:43.995759Z",
     "shell.execute_reply": "2025-04-16T09:52:43.995158Z",
     "shell.execute_reply.started": "2025-04-16T09:52:43.957142Z"
    }
   },
   "source": [
    "If error bars are too high, an alternative visualization is to compare on a fold-by-fold basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9b0a6f-a337-46f8-9003-6c44b6d5017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.algo.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24317553-4b40-44f8-b0b0-f7351b6fd71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = viz.default_colors[6]\n",
    "\n",
    "m = 'auc_test'\n",
    "method1 = 0.7\n",
    "methods = list(set(df_pred.algo.unique()).difference(set([method1])))\n",
    "L = len(methods)\n",
    "\n",
    "xlim = (df_pred[m].min() * 0.9,df_pred[m].max() * 1.05)\n",
    "mask1 = df_pred.algo == method1\n",
    "y_ref = df_pred[mask1].reset_index()\n",
    "\n",
    "fig, axs = plt.subplots(1,L,figsize=(15,3),sharex=True)\n",
    "for i in range(L):\n",
    "    mask2 = df_pred.algo == methods[i]\n",
    "    y_comp = df_pred[mask2].reset_index()\n",
    "\n",
    "    # mask_tot = mask1 & mask2\n",
    "    mask_c = y_ref[m] >= y_comp[m]\n",
    "    if np.sum(mask_c) > 0:\n",
    "        axs[i].scatter(y_ref[m][mask_c],y_comp[m][mask_c],s=100,c='b', edgecolor='black')\n",
    "        axs[i].scatter(y_ref[m][mask_c==False],y_comp[m][mask_c==False],s=100,c='r', edgecolor='black')\n",
    "    else:\n",
    "        axs[i].scatter(y_ref[m],y_comp[m],s=100,c='r', edgecolor='black')\n",
    "    axs[i].set_xlabel(f\"{m} {method1}\")\n",
    "    axs[i].set_ylabel(f\"{m} {methods[i]}\")\n",
    "\n",
    "    axs[i].set_xlim(xlim)\n",
    "    axs[i].set_ylim(xlim)\n",
    "\n",
    "    xs = np.linspace(xlim[0],xlim[1])\n",
    "    axs[i].plot(xs,xs,ls='--',alpha=0.8, color='darkgrey',lw=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# filename = tl.get_filename(f'wto_cv_example_fold_by_fold', lecture_id=lecture_id)\n",
    "filename = None\n",
    "tl.savefig(plt, outfile=filename, outdir=outdir_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9669ac1-335b-41f4-b3b4-7539edfa2259",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(params_cv[0].keys()),params_cv[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "551eedc4-1130-4b76-9244-4666cf735584",
   "metadata": {},
   "source": [
    "And we can now visualize a particular partition to train the model with the full data.\n",
    "\n",
    "We select the model that performs the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf38689-3ae2-4fa8-8d55-3b461d1690ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_cv.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e218521a-c5a4-4944-a9a7-8766549d1083",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    \"assortative\": True,\n",
    "    \"end_file\": \"_mtcov\",\n",
    "    \"out_folder\": '../../../data/outdir/wto/',\n",
    "    \"out_inference\": True,\n",
    "    \"undirected\": True,\n",
    "    \"rseed\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcb066c-539a-4cd5-b776-2828e676b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loglik = True\n",
    "num_realizations = 100\n",
    "max_iter = 1000\n",
    "decision = 2\n",
    "convergence_tol = 1e-4\n",
    "data = data._replace(design_matrix=X_meta)\n",
    "\n",
    "gamma = 0.7\n",
    "for gamma in [0.0,0.7]:\n",
    "    model = MTCOV(num_realizations=num_realizations, plot_loglik=plot_loglik,max_iter=max_iter,decision=decision,convergence_tol=convergence_tol)\n",
    "    params[gamma] = model.fit(data, K=K, gamma=gamma, rng=np.random.default_rng(config_dict[\"rseed\"]), **config_dict)\n",
    "    \n",
    "    algo = f'mtcov_{gamma}_{ref_group}'\n",
    "    u[algo] = params[gamma][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b77868-a80a-40e6-9f81-9f4143449cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "u[algo].shape, u.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3376c39f-57ee-40ec-ad87-f73c27b20b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename0 = f'WTO_network_{algo}_{plot_labels}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9314ead9-f706-448f-bf5a-12a4c3d5ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize= (16,10)\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(16,6))\n",
    "\n",
    "viz.plot_network(data,X_meta,ax=axs[0], title=f'Attribute {attrib_label}')\n",
    "viz.plot_network(data,u['mtcov_0.7_OECD'],ax=axs[1], title = r'$\\gamma=0.7$')\n",
    "viz.plot_network(data,u['mtcov_0.0_OECD'],ax=axs[2], title = 'No attributes')\n",
    "\n",
    "\n",
    "filename = tl.get_filename(f'wto_attribute_{attrib_label}', lecture_id=lecture_id)\n",
    "filename = None\n",
    "tl.savefig(plt, outfile=filename, outdir=outdir_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c225cf73-a3f8-4ef3-ba79-ff4405b40086",
   "metadata": {},
   "source": [
    "## 4.4 Other attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85bf6b1-f259-4e93-93b7-633bd810f523",
   "metadata": {},
   "source": [
    "Try with some other attribute!  \n",
    "\n",
    "For instance, `cc.UNregion` assigns one geographic macro area to each country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83ee358-8098-4e41-a777-b719c76af169",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.UNregion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4247efcb-2431-40cc-ac9d-912565b902d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_area = cc.UNregion['UNregion'].unique()\n",
    "macro_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3485dd-2ee3-459f-b34c-a8e74bfc3346",
   "metadata": {},
   "outputs": [],
   "source": [
    "nameShort2UNregion = dict(zip(cc.UNregion['name_short'],cc.UNregion['UNregion']))\n",
    "nameShort2UNregion['European Union'] = 'Western Europe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209c2de9-f79f-4c35-87f9-f484122d663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "C = len(macro_area) + 1 # if 2: binary\n",
    "X_UN = np.zeros((len(data.nodes),C)).astype(int)\n",
    "\n",
    "for i,n in enumerate(data.nodes):\n",
    "    if nameRaw2Short[n] in nameShort2UNregion:\n",
    "        r = nameShort2UNregion[nameRaw2Short[n]]\n",
    "        idx = np.where(macro_area ==r)[0]\n",
    "        X_UN[i,idx] = 1\n",
    "    else:\n",
    "        print(n)\n",
    "        X_UN[i,-1] = 1\n",
    "        \n",
    "assert np.all(np.sum(X_UN,axis=1) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ebb1a8-1512-4d45-9bdd-608b15462ef6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T11:12:15.148900Z",
     "iopub.status.busy": "2025-04-16T11:12:15.148360Z",
     "iopub.status.idle": "2025-04-16T11:12:15.186417Z",
     "shell.execute_reply": "2025-04-16T11:12:15.186017Z",
     "shell.execute_reply.started": "2025-04-16T11:12:15.148855Z"
    }
   },
   "source": [
    "Now go back in the previous cells and use `X_UN` as node attribute. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ffb785-41bf-41ea-95d0-d1db63d81766",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fc7aeb-f82b-461c-9580-586ab1b19c79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-16T11:22:57.390294Z",
     "iopub.status.busy": "2025-04-16T11:22:57.389625Z",
     "iopub.status.idle": "2025-04-16T11:22:57.426026Z",
     "shell.execute_reply": "2025-04-16T11:22:57.425433Z",
     "shell.execute_reply.started": "2025-04-16T11:22:57.390250Z"
    }
   },
   "source": [
    "Build other attributes from this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab128cce-c088-4902-96bc-2d5f6ba0fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_area = cc.continent['continent'].unique()\n",
    "macro_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac420cc8-7fda-4ef4-9a3c-a3dc084f6c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nameShort2region = dict(zip(cc.continent['name_short'],cc.continent['continent']))\n",
    "nameShort2region['European Union'] = 'Europe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a529ac24-4d64-46e5-a292-132b13d93b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "C = len(macro_area) + 1 # if 2: binary\n",
    "X_reg = np.zeros((len(data.nodes),C)).astype(int)\n",
    "\n",
    "for i,n in enumerate(data.nodes):\n",
    "    if nameRaw2Short[n] in nameShort2region:\n",
    "        r = nameShort2region[nameRaw2Short[n]]\n",
    "        idx = np.where(macro_area ==r)[0]\n",
    "        X_reg[i,idx] = 1\n",
    "    else:\n",
    "        print(n)\n",
    "        X_reg[i,-1] = 1\n",
    "        \n",
    "assert np.all(np.sum(X_reg,axis=1) == 1), np.where(np.sum(X_reg,axis=1) != 1)\n",
    "X_reg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b90a607-af42-4297-b1cd-acbbe93f3c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_labels = False\n",
    "filename = f'wto_x_attributes_{plot_labels}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41c280f-fc5b-4828-8cd2-cc5721583d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize= (16,10)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(12,4))\n",
    "\n",
    "# plot_network(data,u[algo],ax=axs[0])\n",
    "viz.plot_network(data,X,ax=axs[0], title='OECD',plot_labels=plot_labels)\n",
    "viz.plot_network(data,X_UN,ax=axs[1],title='UNregion',plot_labels=plot_labels)\n",
    "viz.plot_network(data,X_reg,ax=axs[2],title='Continent', filename=filename, lecture_id=lecture_id,outdir=outdir_fig,plot_labels=plot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e5b4d6-ac7b-43ea-aa9e-53c9f70015d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
