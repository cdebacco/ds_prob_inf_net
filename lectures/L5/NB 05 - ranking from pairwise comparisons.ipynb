{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "829a333c-75cf-48c2-88a5-0ecbefacc509",
   "metadata": {},
   "source": [
    "# L5: rankings from pairwise comparisons\n",
    "Here we explore how to extract hidden rankings from pairwise comparisons, e.g. games between teams in sport.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111bcd99-22e9-4b7c-88f8-fe3219a7fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bf21c4-bca0-421f-8c44-2e565c3c3590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f2f442-f113-4735-bf94-b05d91feec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../src/')\n",
    "import tools as tl\n",
    "import plot as viz\n",
    "from plot import BLACK\n",
    "import io as io\n",
    "import ranking_tools.springrank as sr\n",
    "import ranking_tools.bradley_terry as bt\n",
    "import ranking_tools.process_input_into_matrix as prcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4617a2a1-6dc2-4352-9e1e-8424d699248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from matplotlib.lines import Line2D\n",
    "from adjustText import adjust_text\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f7d6bc-ed75-4214-a153-b0f5580dbddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "colormap = plt.cm.tab10\n",
    "colors = {i: colormap(i) for i in range(20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb4e93-ce5f-485d-89da-e990c4df2789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv_tools as cvtl\n",
    "from statsbombpy import sb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf121a3-9596-4103-b8bc-603928245c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir_fig = '../figures/'\n",
    "lecture_id = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ca535-63c6-4f14-96be-516d2d4c01f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "prng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32e3a6c-8e43-4853-90a3-995eecbf1f87",
   "metadata": {},
   "source": [
    "# 0. Download code\n",
    "- [SpringRank](https://github.com/LarremoreLab/SpringRank/blob/master/springrank/springrank.py)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e4768f-242a-4ba5-be1f-e2760715a744",
   "metadata": {},
   "source": [
    "# 1. Import data\n",
    "\n",
    "**Source**: download a dataset from [StatsBomb open data](https://github.com/statsbomb/open-data/tree/master).  \n",
    "\n",
    "We will use the python package [`statsbombpy`](https://github.com/statsbomb/statsbombpy) to process the raw data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c21b7e-d05e-42ed-9e1a-a5b79e5aad66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-29T11:26:37.746433Z",
     "iopub.status.busy": "2025-04-29T11:26:37.745766Z",
     "iopub.status.idle": "2025-04-29T11:26:37.780656Z",
     "shell.execute_reply": "2025-04-29T11:26:37.779708Z",
     "shell.execute_reply.started": "2025-04-29T11:26:37.746394Z"
    }
   },
   "source": [
    "We start by downloading matches from at least two different competitions, to be able to compare them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dc3dcf-70c2-4c6d-a8e9-21ca73bdfdf4",
   "metadata": {},
   "source": [
    "## 1.1 Import raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5540d640-4541-46c1-93c3-a41d308bc6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp = sb.competitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6ca30c-c109-4fe0-a72e-7159b02b83ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_comp['competition_international'] == False\n",
    "df_comp = df_comp[mask]\n",
    "competitionId2Name = dict(zip(df_comp['competition_id'],df_comp['competition_name']))\n",
    "df_comp.competition_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff11cb34-a7af-4518-a259-4d69e37da3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_ids = [37,49,12,2,11]\n",
    "season_ids = [90,3,27,27,27]\n",
    "\n",
    "compId2sort = {c: i for i,c in enumerate(competition_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c7338c-3608-460f-8d77-c524e3900d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = {c: sb.matches(competition_id=c, season_id=season_ids[i]) for i, c in enumerate(competition_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca816c9-46ed-4b69-8b75-3692c75b8c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['match_id', 'match_date','home_team', 'away_team', 'home_score', 'away_score']\n",
    "games[49][cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b074d39a-9285-4e34-901a-16959baac063",
   "metadata": {},
   "source": [
    "## 1.2 Process into a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493e0516-ccfe-463d-b18c-064218585c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {competition_id: prcs.process_games(games[competition_id]) for competition_id in competition_ids}\n",
    "\n",
    "A, encoder_teams = {}, {}\n",
    "for k,v in df.items():\n",
    "    A[k],encoder_teams[k] = prcs.df2matrix(v,score_label='points',method='points')\n",
    "    print(k,A[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8e2748-804e-4929-a9ef-2579f805fb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_points(df: pd.DataFrame, competition_id: int = None):\n",
    "    '''\n",
    "    Get total number of points for each team\n",
    "    '''\n",
    "    df_home = df.groupby(by=['home_team'])['home_points'].agg(['count','sum']).reset_index()\n",
    "    df_home.rename(columns={'home_team':'node_label', 'count':'n_matches','sum': 'points'},inplace=True)\n",
    "    df_away = df.groupby(by=['away_team'])['away_points'].agg(['count','sum']).reset_index()\n",
    "    df_away.rename(columns={'away_team':'node_label', 'count':'n_matches','sum': 'points'},inplace=True)\n",
    "    \n",
    "    df_points = pd.concat([df_home,df_away]).reset_index().groupby(by=['node_label'])[['points','n_matches']].agg(['sum']).droplevel(1,axis=1).reset_index()\n",
    "    df_points.loc[:,'points_prg'] = (df_points['points'] / df_points['n_matches']).map(lambda x: np.round(x,2))\n",
    "    df_points = df_points.sort_values(by='points_prg',ascending=False).reset_index(drop=True)\n",
    "    if competition_id is not None:\n",
    "        df_points.loc[:,'competition_id'] = competition_id\n",
    "        \n",
    "    return df_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b241e1ac-73dd-42cb-ba79-1eb06b418d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_points_comp = {k: get_points(v, competition_id=k) for k,v in df.items()}\n",
    "df_points = pd.concat(df_points_comp.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4530ed2a-b25e-4cbc-8d9c-404d9fee4c36",
   "metadata": {},
   "source": [
    "# 2. Run ranking models\n",
    "\n",
    "We can proceed by learning scores from the outcomes of matches "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2208d9d-9a56-42e1-b5ca-113101f1c6c9",
   "metadata": {},
   "source": [
    "## 2.1 SpringRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35454163-0989-4f74-8f7f-3c09bbd79cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit model\n",
    "model = {}\n",
    "scaled_ranks = {}\n",
    "stats = []\n",
    "for k,v in A.items():\n",
    "    model[k] = sr.SpringRank()\n",
    "    model[k].fit(v)\n",
    "    scaled_ranks[k] = model[k].get_rescaled_ranks(0.75) # Get the scaled ranks so that a one-rank difference means a 75% win rate\n",
    "    d = [k,competitionId2Name[k],model[k].get_beta(),model[k].depth, model[k].n_levels,model[k].delta_beta]\n",
    "    stats.append(d)\n",
    "df_stats = pd.DataFrame(stats, columns = ['competition_id','competition_name', 'beta','depth','n_levels','delta_level'])\n",
    "df_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739dd18f-f51d-4079-ae64-7cb8ce731ea0",
   "metadata": {},
   "source": [
    "## 2.2 Bradley-Terry model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca794398-0f64-41c8-b2f9-ccf4de472157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit model\n",
    "model_bt = {}\n",
    "scaled_ranks_bt = {}\n",
    "for k,v in A.items():\n",
    "    model_bt[k] = bt.BradleyTerry()\n",
    "    model_bt[k].fit(v, method='em')\n",
    "    scaled_ranks_bt[k] = np.exp(model_bt[k].ranks)\n",
    "    scaled_ranks_bt[k] = model_bt[k].get_rescaled_ranks(0.75) # Get the scaled ranks so that a one-rank difference means a 75% win rate\n",
    "    # scaled_ranks_bt[k] /= scaled_ranks_bt[k].max() # invariant rescaling to have the max score=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bdf12d-7dac-41e7-b49e-435f853dcce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeLabel2Id = {k: {c:i for i,c in enumerate(v.classes_)} for k,v in encoder_teams.items()}\n",
    "nodeId2Label = {k: {i:c for i,c in enumerate(v.classes_)} for k,v in encoder_teams.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f871e6-36be-45de-bba8-49a5b051b2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_res = pd.concat([pd.DataFrame({'node_id': np.arange(model[k].ranks.shape[0]),'node_label': [nodeId2Label[k][i] for i in np.arange(model[k].ranks.shape[0])], 'score': model[k].ranks, 'competition_id': [k for j in range(len(model[k].ranks))]})\n",
    "#            for k in model.keys()])\n",
    "show_rescaled = True\n",
    "fig_label = 'rescaled' if show_rescaled == True else 'not_rescaled'\n",
    "if show_rescaled == True:\n",
    "    df_res = pd.concat([pd.DataFrame({'node_id': np.arange(v.shape[0]),'node_label': [nodeId2Label[k][i] for i in np.arange(v.shape[0])], 'score_sr': v, 'competition_id': [k for j in range(len(v))]})\n",
    "               for k,v in scaled_ranks.items()])\n",
    "    df_res_bt = pd.concat([pd.DataFrame({'node_id': np.arange(v.shape[0]),'node_label': [nodeId2Label[k][i] for i in np.arange(v.shape[0])], 'score_bt': v, 'competition_id': [k for j in range(len(v))]})\n",
    "               for k,v in scaled_ranks_bt.items()])\n",
    "    df_res = df_res.merge(df_res_bt, on =['node_id','node_label','competition_id'])\n",
    "else:\n",
    "    df_res = pd.concat([pd.DataFrame({'node_id': np.arange(v.ranks.shape[0]),'node_label': [nodeId2Label[k][i] for i in np.arange(v.ranks.shape[0])], 'score_sr': v.ranks, 'competition_id': [k for j in range(len(v.ranks))]})\n",
    "               for k,v in model.items()])\n",
    "    df_res_bt = pd.concat([pd.DataFrame({'node_id': np.arange(v.ranks.shape[0]),'node_label': [nodeId2Label[k][i] for i in np.arange(v.ranks.shape[0])], 'score_bt': v.ranks, 'competition_id': [k for j in range(len(v.ranks))]})\n",
    "               for k,v in model.items()])\n",
    "    df_res = df_res.merge(df_res_bt, on =['node_id','node_label','competition_id'])\n",
    "# df_res.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef25a843-78de-4459-9317-352908a3eb81",
   "metadata": {},
   "source": [
    "Let's get aggregate statistics to characterize the distributions per league"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305dbd3e-3cba-4358-aa40-f78476cfb470",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = 'sr'\n",
    "metric = f'score_{algo}'\n",
    "df_plot_dist = df_res.groupby(by='competition_id')[metric].agg(['describe']).droplevel(0,axis=1).reset_index().sort_values(by='competition_id',key=lambda x: x.map(compId2sort))\n",
    "df_plot_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c08aab-4b95-4888-9d9f-c0d239f09428",
   "metadata": {},
   "source": [
    "# 3. Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfbeac5-4770-4c50-af8d-52606f5c2b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = viz.default_colors_dict['blue_dark']\n",
    "ms = 200\n",
    "colors = [viz.default_colors_dict['blue_sb_dark'], viz.default_colors_dict['green_forest'],viz.default_colors_dict['red_adobe'],\n",
    "          viz.default_colors_dict['yellow_sand'],viz.default_colors_dict['purple'],viz.default_colors_dict['dark_grey'],viz.default_colors_dict['purple_sb_dark']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5441662-d971-4b77-8f31-cb0c2239068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ylabels = [competitionId2Name[c] for c in df_plot_dist['competition_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e01537-81b3-4242-92df-b319e2a3479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'sr':'SpringRank','bt':'Bradley-Terry','points_prg':'Points per game'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bbc319-d175-4722-8148-261a6b21d7a5",
   "metadata": {},
   "source": [
    "Plot score distribution over different leagues "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d120b2c5-723a-4d66-a2d5-2e984d92ad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = f'{label_dict[algo]} scores from soccer matches'\n",
    "point_label = 'node_label'\n",
    "nmax = min(200,len(df_plot_dist))\n",
    "n_display_max = 10\n",
    "fig, ax = plt.subplots(1,1, figsize=(8,8))\n",
    "\n",
    "xs = np.arange(len(df_plot_dist), 0,-1)\n",
    "plt.hlines(xs[:nmax],xmin=df_plot_dist[:nmax]['min'],xmax=df_plot_dist[:nmax]['max'], alpha=0.7, color = mc, lw = 2, ls='-',zorder=1)\n",
    "plt.scatter(df_plot_dist[:nmax]['max'], xs[:nmax],s=ms, alpha=0.6, c = viz.default_colors_dict['blue_dark'],edgecolors=BLACK,zorder=5)\n",
    "plt.scatter(df_plot_dist[:nmax]['min'], xs[:nmax],s=ms, alpha=0.6, c = viz.default_colors_dict['blue'],edgecolors=BLACK,zorder=5)\n",
    "\n",
    "'''\n",
    "Inidividual points\n",
    "'''\n",
    "ylabels = []\n",
    "teams_to_display = []\n",
    "for i, cid in enumerate(competition_ids):\n",
    "    g = df_res[df_res.competition_id == cid]\n",
    "    l = len(g)\n",
    "    x_data = np.array([xs[i]] * l)\n",
    "    x_jittered = np.array([x + st.t(df=6, scale=0.08).rvs(1) for x in x_data])\n",
    "    xjit2name = dict(zip(g[point_label],x_jittered))\n",
    "\n",
    "    x = np.array(g[metric])\n",
    "    clustering = AffinityPropagation(random_state=5).fit(x.reshape(-1, 1))\n",
    "    clabels = clustering.labels_\n",
    "    n_clusters = len(np.unique(clabels))\n",
    "\n",
    "    cs = [colors[k] for k in clabels]\n",
    "    plt.scatter(g[metric], x_jittered,s=50, alpha=0.8, c = cs,edgecolors=BLACK,zorder=1)\n",
    "\n",
    "    msg = f\"{sorted_ylabels[i]} (n={l})\".replace(\"Women's\",'')\n",
    "    msg = f\"{msg}\\nbeta = {model[cid].get_beta():.2f}\"\n",
    "    msg = msg.replace(\"Women\",'')\n",
    "    ylabels.append(f\"{msg}\")\n",
    "\n",
    "    # select points to annotate\n",
    "    cond1 = g[metric] >= g[metric].quantile(0.80)\n",
    "    cond2 = g[metric] <= g[metric].quantile(0.20)\n",
    "    mask = np.logical_or(cond1,cond2)\n",
    "    n_display = min(n_display_max, np.sum(mask))\n",
    "    \n",
    "    for i in range(n_display):\n",
    "        df_tmp = g[mask].sort_values(by=[metric], ascending=False)\n",
    "        # idx = df_tmp.index[i]\n",
    "        tname = df_tmp.iloc[i][point_label]\n",
    "        y = df_tmp.iloc[i][metric]\n",
    "        x = x_jittered[mask][i]\n",
    "        # players_to_display.append([x, y, tname])\n",
    "        teams_to_display.append([y,xjit2name[tname],tname])\n",
    "\n",
    "# ------------ marker annotation ----------------------------------------------\n",
    "ts = []\n",
    "for d in teams_to_display:\n",
    "    msg = f\"{d[2]}\"\n",
    "    ts.append(ax.text(d[0], d[1], msg, fontsize=8, zorder=1))\n",
    "adjust_text(ts, force_text=(0.5, 0.5),\n",
    "\t\t\t\tarrowprops=dict(arrowstyle='-|>', color='black', connectionstyle=\"arc3,rad=-.5\", zorder=10),\n",
    "\t\t\t\tax=ax)\n",
    "# ----------------------------------------------------------\n",
    "lines = [Line2D([0], [0], color=c,  marker='o', mec=\"w\", linestyle='', markersize=15,) for c in [viz.default_colors_dict['blue'],viz.default_colors_dict['blue_dark']]]\n",
    "plt.legend(lines,['Min','Max'] , labelcolor= '#101628',bbox_to_anchor=(0.8, 1.0), loc=\"lower center\",ncols = 2,frameon=False, fontsize= 14)\n",
    "\n",
    "plt.yticks(xs[:nmax],ylabels[:nmax],fontsize=12)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.xlabel('Score',fontsize=14)\n",
    "plt.gca().grid(axis='x')\n",
    "\n",
    "msg = f\"{title}\"\n",
    "fig.text(0,1.,msg,fontweight=\"normal\",fontsize=24,ha=\"left\",color=viz.default_colors_dict['red'])\n",
    "\n",
    "subtitle = f\"Scores are calculate from games' results in terms of score difference.\\nMarker colors are clusters of teams with similar scores.\"\n",
    "fig.text(\n",
    "    0., 0.0, f\"{subtitle}\", size=11,\n",
    "    color=\"#000000\",\n",
    "    ha=\"left\"\n",
    ")\n",
    "plt.tight_layout()\n",
    "\n",
    "filename = tl.get_filename(f'soccer_{algo}_{fig_label}', lecture_id=lecture_id)\n",
    "filename = None\n",
    "tl.savefig(plt, outfile=filename, outdir=outdir_fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4f4536-b9a0-4d8e-9cc5-9fe490d89d5a",
   "metadata": {},
   "source": [
    "## 3.1 How is this related to the actual points attained by each team?\n",
    "\n",
    "Let's merge datasets of learned scores and official league standings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0749c92c-8448-4e41-9c55-b56bf444f0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot = df_res.merge(df_points,on=['node_label','competition_id']).sort_values(by='points_prg',ascending=False).reset_index(drop=True)\n",
    "df_tot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e3254d-59c1-4091-9ca8-ccd60c33b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "algo = 'sr'\n",
    "x = f'score_{algo}'\n",
    "y = 'points_prg'\n",
    "plot_linear_regression = True\n",
    "for i, (n,g) in enumerate(df_tot.groupby(by='competition_id')):\n",
    "    spearman_coef = spearmanr(g[x],g[y])[0]\n",
    "    pearson_coef = pearsonr(g[x],g[y])[0]\n",
    "    msg = f\"{competitionId2Name[n]}, sp = {spearman_coef:.2f} | pr = {pearson_coef:.2f}\"\n",
    "    ax.scatter(g[x],g[y],c=colors[i],label=msg)\n",
    "    # ----------------------------------------------\n",
    "    if plot_linear_regression == True:\n",
    "        m, b = np.polyfit(list(g[x]), list(g[y]), 1)\n",
    "        xmin, xmax, ymin, ymax = plt.axis()\n",
    "        xs = np.linspace(xmin, xmax, 100)\n",
    "        ax.plot(xs, m * xs + b, ls='--', c=colors[i], alpha=0.8, lw=1)\n",
    "    # ----------------------------------------------\n",
    "ax.set_xlabel(f\"Score {algo.upper()}\")\n",
    "ax.set_ylabel(label_dict[y])\n",
    "plt.legend(loc='best',fontsize=10)\n",
    "\n",
    "filename = tl.get_filename(f'soccer_{algo}_vs_points', lecture_id=lecture_id)\n",
    "filename = None\n",
    "tl.savefig(plt, outfile=filename, outdir=outdir_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce530d7c-ee08-4f6a-8ddd-0774cf9cbc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_points_comp[49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862ba95c-be18-4413-af0c-588eb0e8c905",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 49\n",
    "x = 'score_sr'\n",
    "y = 'points_prg'\n",
    "plot_linear_regression = True\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "\n",
    "g = df_tot[df_tot.competition_id==k]\n",
    "spearman_coef = spearmanr(g[x],g[y])[0]\n",
    "pearson_coef = pearsonr(g[x],g[y])[0]\n",
    "msg = f\"{competitionId2Name[k]}, sp = {spearman_coef:.2f} | pr = {pearson_coef:.2f}\"\n",
    "ax.scatter(g[x],g[y],c=colors[i],label=msg)\n",
    "\n",
    "# ------------ marker annotation ----------------------------------------------\n",
    "ts = []\n",
    "for idx,row in g.iterrows():\n",
    "    msg = f\"{row['node_label']}\"\n",
    "    ts.append(ax.text(row[x], row[y], msg, fontsize=8, zorder=1))\n",
    "adjust_text(ts, force_text=(0.5, 0.5),\n",
    "\t\t\t\tarrowprops=dict(arrowstyle='-|>', color='black', connectionstyle=\"arc3,rad=-.5\", zorder=10),\n",
    "\t\t\t\tax=ax)\n",
    "# ----------------------------------------------\n",
    "if plot_linear_regression == True:\n",
    "    m, b = np.polyfit(list(g[x]), list(g[y]), 1)\n",
    "    xmin, xmax, ymin, ymax = plt.axis()\n",
    "    xs = np.linspace(xmin, xmax, 100)\n",
    "    ax.plot(xs, m * xs + b, ls='--', c='grey', alpha=0.8, lw=1)\n",
    "# ----------------------------------------------\n",
    "\n",
    "ax.set_xlabel(x)\n",
    "ax.set_ylabel(y)\n",
    "plt.legend(loc='best',fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e83dcd-4af6-46c0-a14f-21cd4e9d762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 49\n",
    "ref_team_name = 'North Carolina Courage'\n",
    "cond1 = df[k].home_team == ref_team_name\n",
    "cond2 = df[k].away_team == ref_team_name\n",
    "cond3 = df[k].home_score != df[k].away_score\n",
    "mask = (cond1 | cond2) & cond3\n",
    "df[k][mask][cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e83652-21ab-42a5-b445-9f549d3747f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 49\n",
    "delta_x = 0.2\n",
    "q = 0.75\n",
    "fig,ax = plt.subplots(1,1,figsize=(6,6))\n",
    "\n",
    "\n",
    "viz.plot_score_network(A[k],model[k].ranks,cm = colormap,ax=ax,plot_labels=True,\n",
    "                      nodeId2Label=nodeId2Label[k])\n",
    "\n",
    "# --- Plot levels\n",
    "delta_ref = model[k].ranks.max() - model[k].ranks.min()\n",
    "delta_beta = (np.log(q/(1-q)))/(2*model[k].beta)\n",
    "ys = np.linspace(model[k].ranks.min(),model[k].ranks.max(),100)\n",
    "xs = delta_x * np.ones(ys.shape[0])\n",
    "ax.plot(xs,ys,lw=1,color=viz.default_colors_dict['blue_sb_dark'])\n",
    "B = int(np.ceil(delta_ref/delta_beta))\n",
    "ys = np.arange(model[k].ranks.min(),model[k].ranks.min() + B * delta_beta,delta_beta)\n",
    "xs = delta_x * np.ones(ys.shape[0])\n",
    "ax.scatter(xs,ys,lw=1,marker = '_',color=viz.default_colors_dict['blue_sb_dark'])\n",
    "# ---------\n",
    "plt.tight_layout()\n",
    "filename = tl.get_filename(f'soccer_{algo}_{k}_scores', lecture_id=lecture_id)\n",
    "filename = None\n",
    "tl.savefig(plt, outfile=filename, outdir=outdir_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3348ae-6e1e-4bd6-b85f-bad7d5b3a1f4",
   "metadata": {},
   "source": [
    "## 3.2 Simulate games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee159871-dfc9-49c5-a5bb-006d8ddffb1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T13:05:24.831982Z",
     "iopub.status.busy": "2025-04-30T13:05:24.831349Z",
     "iopub.status.idle": "2025-04-30T13:05:24.866462Z",
     "shell.execute_reply": "2025-04-30T13:05:24.865880Z",
     "shell.execute_reply.started": "2025-04-30T13:05:24.831937Z"
    }
   },
   "source": [
    "We are ready to generate games from the main model parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc3254d-9426-4fd1-af2b-2fd518b4ba98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_H(s: np.ndarray, l: float = 1):\n",
    "    N = s.shape[0]\n",
    "    H = np.zeros((N,N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            if i != j:\n",
    "                H[i,j] = 0.5 * (s[i]-s[j] - l)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198d7094-990c-4f21-9b7c-547a5ab1642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 49\n",
    "# beta = 10.1\n",
    "# c = 1\n",
    "beta = model[k].beta\n",
    "\n",
    "H = get_H(model[k].ranks)\n",
    "lambda_pois = np.exp(beta * H)\n",
    "np.fill_diagonal(lambda_pois,0)\n",
    "c = np.sum(lambda_pois) / np.sum(A[k])\n",
    "\n",
    "SAMPLE = 1000\n",
    "A_sim = np.array([prng.poisson(lambda_pois) for s in np.arange(SAMPLE)])\n",
    "\n",
    "A_sim_avg = np.mean(A_sim, axis=0)\n",
    "np.fill_diagonal(A_sim_avg,0)\n",
    "A_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10e4c2f-0787-4148-9d84-e49e5e6c2bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(8,4))\n",
    "\n",
    "node_order = np.argsort(-model[k].ranks)\n",
    "viz.plot_matrix(A[k],ax=ax[0],node_order=node_order,title=f\"GT data\")\n",
    "viz.plot_matrix(A_sim_avg,ax=ax[1],node_order=node_order,title=f\"Estimated average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f77883d-50d4-4a46-bc8d-3b3ad7f3abcd",
   "metadata": {},
   "source": [
    "We can select one example sample and check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b895850d-fd31-44e2-9cb6-2cd6c251d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 49\n",
    "fig,ax = plt.subplots(1,1,figsize=(6,6))\n",
    "\n",
    "idx = prng.choice(np.arange(SAMPLE)) # random sample\n",
    "viz.plot_score_network(A_sim[0],model[k].ranks,cm = colormap,ax=ax,plot_labels=True,\n",
    "                      nodeId2Label=nodeId2Label[k],x_jit=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80602cc1-f2e2-4352-b6b0-639730427edf",
   "metadata": {},
   "source": [
    "What happens if you change the hyperparameters?\n",
    "\n",
    "Note that this makes sense if you do not have a fixed schedule, and you want to generate that as well.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04892ca5-b5ee-45c7-bbdb-f447829da6d5",
   "metadata": {},
   "source": [
    "### 3.2.1 La Liga\n",
    "The top 3 teams are very close to each other. What is the probability that one of them wins the league if we were to simulate it n times?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1854627b-1d01-4914-975f-ad9a7e7dc02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 11\n",
    "\n",
    "# beta = 10.1\n",
    "# c = 1\n",
    "beta = model[k].beta\n",
    "\n",
    "H = get_H(model[k].ranks)\n",
    "lambda_pois = np.exp(beta * H)\n",
    "np.fill_diagonal(lambda_pois,0)\n",
    "c = np.sum(lambda_pois) / np.sum(A[k])\n",
    "\n",
    "SAMPLE = 1000\n",
    "A_sim = np.array([prng.poisson(lambda_pois) for s in np.arange(SAMPLE)])\n",
    "\n",
    "A_sim_avg = np.mean(A_sim, axis=0)\n",
    "np.fill_diagonal(A_sim_avg,0)\n",
    "A_sim.shape,c,beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2001b7-15bc-4a95-8838-667d6e5fee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,3,figsize=(8,4))\n",
    "\n",
    "node_order = np.argsort(-model[k].ranks)\n",
    "viz.plot_matrix(A[k],ax=ax[0],node_order=node_order, title = f\"GT data\")\n",
    "idx = prng.choice(np.arange(SAMPLE))\n",
    "viz.plot_matrix(A_sim[idx],ax=ax[1],node_order=node_order, title = f\"Example sample {idx}\")\n",
    "viz.plot_matrix(A_sim_avg,ax=ax[2],node_order=node_order, title = f\"Estimated average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da78e6d-bf2d-4d79-a536-5f9dc32f9783",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T13:23:13.658144Z",
     "iopub.status.busy": "2025-04-30T13:23:13.656907Z",
     "iopub.status.idle": "2025-04-30T13:23:13.695362Z",
     "shell.execute_reply": "2025-04-30T13:23:13.694775Z",
     "shell.execute_reply.started": "2025-04-30T13:23:13.658068Z"
    }
   },
   "source": [
    "Alternatively, we can take every match in the schedule and simulate who wins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d0ef51-93a4-42b7-816b-e5cbb20dd80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simulated_games_df(df: pd.DataFrame,ranks: pd.DataFrame, nodeLabel2Id: dict,\n",
    "                          beta: float = 1, competition_id: int=None):\n",
    "\n",
    "    cols = ['home_team','away_team']#,'home_score','away_score','score_diff','home_points','away_points']\n",
    "    score_diff = []\n",
    "    df_new = df[cols].copy(deep=True)\n",
    "    for c in 'home_points','away_points':\n",
    "        df_new.loc[:,c] = 0\n",
    "        \n",
    "    for idx, rows in df_new.iterrows():\n",
    "\n",
    "        i = nodeLabel2Id[rows['home_team']]\n",
    "        j = nodeLabel2Id[rows['away_team']]\n",
    "        s_i = ranks[i]\n",
    "        s_j = ranks[j]\n",
    "\n",
    "        p_ij = 1/ (1+ np.exp(-beta* (s_i-s_j)))\n",
    "        r = st.bernoulli.rvs(p_ij, size=1)\n",
    "        if r == 1:\n",
    "            df_new.loc[idx,'home_points'] = 3\n",
    "        elif r == 0:\n",
    "            df_new.loc[idx,'away_points'] = 3\n",
    "        else:\n",
    "            print(f'r={r}')\n",
    "    if competition_id is not None:\n",
    "        df_new.loc[:,'competiton_id'] = k\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b1e1c0-443e-4109-8d6c-eee5a3927d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE = 100\n",
    "df_sim = [get_simulated_games_df(df[k],model[k].ranks,nodeLabel2Id[k],beta=model[k].beta, competition_id=k) for s in range(SAMPLE)]\n",
    "df_points_sim = [get_points(d, competition_id=k) for d in df_sim]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0287f7-8e03-430b-9be6-c990ce932481",
   "metadata": {},
   "source": [
    "Let's check one particular (arbitrary) sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41f588a-d910-4ec8-98ed-417c201a7931",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = prng.choice(np.arange(SAMPLE))\n",
    "df_points_sim[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160c6d0a-ea81-413f-bec1-b698bf331772",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-30T13:41:22.013577Z",
     "iopub.status.busy": "2025-04-30T13:41:22.013020Z",
     "iopub.status.idle": "2025-04-30T13:41:22.045827Z",
     "shell.execute_reply": "2025-04-30T13:41:22.045160Z",
     "shell.execute_reply.started": "2025-04-30T13:41:22.013551Z"
    }
   },
   "source": [
    "We can now count how many times in each of the simulated standing, one of the top 3 teams wins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c08425-ebdc-4a79-b939-001db49c2cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_ids = np.argsort(-model[k].ranks)[:3]\n",
    "top3_labels = [nodeId2Label[k][i] for i in top3_ids]\n",
    "top3_labels,model[k].ranks[top3_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba7399-2088-41a5-8a40-92b772831e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_ranks_top3 = np.zeros((len(top3_labels),len(top3_labels))).astype(int)\n",
    "for rid, ref_team in enumerate(top3_labels):\n",
    "    for df_tmp in df_points_sim:\n",
    "        idx_sim = df_tmp[df_tmp.node_label == ref_team].index[0]\n",
    "        if idx_sim < len(top3_labels):\n",
    "            sim_ranks_top3[rid,idx_sim] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26262d31-cd8f-4b45-bc3b-41a8c34290cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(sim_ranks_top3, columns = ['n_1st','n_2nd','n_3rd'], index=top3_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de82141-2518-4df5-94c2-9d06e069a56f",
   "metadata": {},
   "source": [
    "What are we missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa43992-736a-41ea-9d9c-fa5096cf76f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_points_comp[k].iloc[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45670c47-881f-4a3d-977f-7e77a76fab50",
   "metadata": {},
   "source": [
    "# 4. Depth of competition\n",
    "\n",
    "We can compare the statistics of the soccer league with results of other types of datasets.   \n",
    "We take Table S2 [https://arxiv.org/pdf/1709.09002](of the SpringRank paper) for other datasets.\n",
    "                                                                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebd852c-8eab-4ad1-a9e5-bc5f10be6f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 0.75\n",
    "dataset = ['parakeet G1', 'parakeet G2','Asian elephants','Business','Computer Science','History','Village 1','Village 2']\n",
    "betas_S2 = np.array([2.7,2.78,2.33,2.04,2.23,2.39,1.98,1.89])\n",
    "depth_S2 = np.array([2.604,1.879,3.,2.125,2.423,2.234,3.618,3.749])\n",
    "delta_level_S2 = np.array([np.log(q / (1 - q)) / (2 * beta) for beta in betas_S2])\n",
    "df_S2 = pd.DataFrame({'competition_id': [i + 100 for i in range(len(dataset))],'competition_name':dataset,\n",
    "                      'beta':betas_S2,'depth':depth_S2,'n_levels':sr.calculate_n_levels(depth_S2,betas_S2),\n",
    "                      'delta_level':delta_level_S2})\n",
    "df_stats2 = pd.concat([df_stats,df_S2],axis=0).drop_duplicates()\n",
    "df_stats2\n",
    "                    \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d49f22-70e0-4183-b5d4-b21fa17f1c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_type = ['Soccer','Parakeet','Elephant','Faculty hiring','Villages']\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "x = 'beta'\n",
    "y= 'n_levels'\n",
    "color_plot = [colors[0] for i in range(5)] + [colors[1] for i in range(2)] + [colors[2] for i in range(1)] + [colors[3] for i in range(3)] + [colors[4] for i in range(2)]\n",
    "fig,ax = plt.subplots(1,1,figsize=(8,4))\n",
    "ax.bar(np.arange(len(df_stats2)),height=df_stats2[y],color = color_plot, width = 0.8, alpha=0.8)\n",
    "ax.set_xlabel('Dataset')\n",
    "ax.set_ylabel('Number of levels')\n",
    "x_tick_labels = df_stats2['competition_name'].values\n",
    "x_tick_labels[0] = 'FA WSL'\n",
    "\n",
    "ax.set_xticks(np.arange(len(df_stats2)), labels = x_tick_labels, fontsize=8, rotation =60)\n",
    "\n",
    "legend_elements = [\n",
    "                   Line2D([0], [0], marker='o', color=colors[i], label=dataset_type[i],\n",
    "                          markerfacecolor=colors[i], markersize=10, lw=0)\n",
    "                    for i in np.arange(len(dataset_type))\n",
    "                    ]\n",
    "ax.legend(handles=legend_elements, loc='best')\n",
    "ax.grid(axis='y')\n",
    "\n",
    "filename = tl.get_filename(f'depth_competition_{algo}', lecture_id=lecture_id)\n",
    "filename = None\n",
    "tl.savefig(plt, outfile=filename, outdir=outdir_fig)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f39083-32ea-4539-bd1a-eda778065d52",
   "metadata": {},
   "source": [
    "# 5. Model selection\n",
    "\n",
    "How do we determine what scoring system is the best?\n",
    "\n",
    "**Homework**!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e11717d-43d3-46d6-9591-96f6492e8694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
