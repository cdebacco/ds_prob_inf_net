{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "829a333c-75cf-48c2-88a5-0ecbefacc509",
   "metadata": {},
   "source": [
    "# L4: VI and mixed-membership mixture models\n",
    "\n",
    "Here we explore how to use Variational Inference to learn parameters in mixed-membership models.  \n",
    "We compare with MLE + EM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111bcd99-22e9-4b7c-88f8-fe3219a7fd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bf21c4-bca0-421f-8c44-2e565c3c3590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import scipy.special as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f2f442-f113-4735-bf94-b05d91feec56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../src/')\n",
    "import tools as tl\n",
    "import plot as viz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f7d6bc-ed75-4214-a153-b0f5580dbddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "colormap = plt.cm.tab10\n",
    "colors = {i: colormap(i) for i in range(20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925f524e-d118-40c7-ab46-524a4037506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from probinet.input.loader import build_adjacency_from_file\n",
    "from probinet.input.stats import print_graph_stats\n",
    "from probinet.models.mtcov import MTCOV\n",
    "from probinet.visualization.plot import plot_hard_membership, plot_soft_membership\n",
    "from probinet.visualization.plot import extract_bridge_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfb4e93-ce5f-485d-89da-e990c4df2789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv_tools as cvtl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a8035a-c313-4a5f-aae3-bc62fbda9bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import country_converter as coconv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf121a3-9596-4103-b8bc-603928245c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir_fig = '../figures/'\n",
    "lecture_id = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856ca535-63c6-4f14-96be-516d2d4c01f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "prng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805fc6c7-98c3-4a91-810b-b78b6255e0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = coconv.CountryConverter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e4768f-242a-4ba5-be1f-e2760715a744",
   "metadata": {},
   "source": [
    "# 1. Setup algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e278ae-e214-4c79-8bff-b3f21ed83288",
   "metadata": {},
   "source": [
    "## 1.1 MLE + EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c3a97c-910a-4742-aaea-ccafba1ec268",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMF_EM(object):\n",
    "    \n",
    "    def __init__(self, A, K=3, is_directed = False):\n",
    "        self.A = A                 # data\n",
    "        self.K = K                 # number of communities\n",
    "        self.N = self.A.shape[0]   # number of nodes\n",
    "        self.is_directed = is_directed\n",
    "\n",
    "    def _init(self, prng,u0=None):\n",
    "        if u0 is None:\n",
    "            self.u = prng.random_sample((self.N, self.K))\n",
    "        if self.is_directed == False:\n",
    "            self.v = self.u\n",
    "        else:\n",
    "            self.v = prng.random_sample((self.N, self.K))\n",
    "        # self.C = prng.random_sample((self.K, self.K))\n",
    "        self.C = np.zeros((self.K,self.K))\n",
    "        np.fill_diagonal(self.C, 1)\n",
    "        \n",
    "    def fit(self, prng, N_real=15, max_iter=500, tol=0.1, decision=2, verbose=True, u0=None):\n",
    "        maxL = - 1e12  # initialization of the maximum likelihood\n",
    "\n",
    "        for r in range(N_real):\n",
    "            # random initialization\n",
    "            self._init(prng,u0=u0)\n",
    "            \n",
    "            # convergence local variables\n",
    "            coincide, it = 0, 0\n",
    "            convergence = False\n",
    "\n",
    "            loglik_values = []  # keep track of the values of the loglik to plot\n",
    "            loglik = - 1e12  # initialization of the loglik\n",
    "\n",
    "            while not convergence and it < max_iter:\n",
    "                self._em()\n",
    "                it, loglik, coincide, convergence = self.check_for_convergence(it, loglik, coincide, convergence, tolerance=tol, decision=decision)\n",
    "                loglik_values.append(loglik)\n",
    "            if verbose == True: print(f'Nreal = {r} - Loglikelihood = {tl.fl(loglik)} - Best Loglikelihood = {tl.fl(maxL)} - iterations = {it} - ')\n",
    "    \n",
    "            if maxL < loglik:\n",
    "                u_f,v_f,C_f = self.update_optimal_parameters()\n",
    "                maxL = loglik\n",
    "                final_it = it\n",
    "                best_loglik_values = list(loglik_values)\n",
    "        \n",
    "        return u_f, v_f, C_f, best_loglik_values\n",
    "\n",
    "    def _em(self):\n",
    "        # E-step\n",
    "        q = self.update_q()\n",
    "        # M-step\n",
    "        # self.C = self.update_C(q)\n",
    "        # q = self.update_q()\n",
    "        self.u = self.update_u(q)\n",
    "        q = self.update_q()\n",
    "        if self.is_directed == False:\n",
    "            self.v = self.u\n",
    "        else:\n",
    "            self.v = self.update_v(q)\n",
    "            q = self.update_q()\n",
    "\n",
    "    def update_q(self):\n",
    "        lambda_ij = np.einsum('ik,jq,kq-> ijkq', self.u, self.v, self.C)\n",
    "        lambda_ij_den = np.einsum('ijkq -> ij', lambda_ij)\n",
    "        return lambda_ij/lambda_ij_den[:,:,np.newaxis,np.newaxis]\n",
    "    \n",
    "    def update_u(self, q):\n",
    "        numerator = 0.1 + np.einsum('ij,ijkq->ik', self.A, q)\n",
    "        denominator = 0.1 + np.einsum('q,kq->k', self.v.sum(axis=0), self.C)[np.newaxis,:]\n",
    "        u_temp = numerator / denominator\n",
    "        return u_temp\n",
    "\n",
    "    def update_v(self, q):\n",
    "        numerator = np.einsum('ij,ijkq->jq', self.A, q)\n",
    "        denominator = np.einsum('k,kq->q', self.u.sum(axis=0), self.C)[np.newaxis,:]\n",
    "        v_temp = numerator / denominator\n",
    "        return v_temp\n",
    "\n",
    "    def update_C(self, q):\n",
    "        numerator = 0.1 + np.einsum('ij,ijkq->kq', self.A, q)\n",
    "        denominator = 0.1 + np.einsum('k,q->kq', self.u.sum(axis=0), self.v.sum(axis=0))\n",
    "        C_temp = numerator / denominator\n",
    "        return C_temp\n",
    "    \n",
    "    def check_for_convergence(self, it, loglik, coincide, convergence, tolerance=0.1, decision=2):\n",
    "        if it % 10 == 0:\n",
    "            old_L = loglik\n",
    "            loglik = self.Likelihood(EPS = 1e-12)\n",
    "            if abs(loglik - old_L) < tolerance:\n",
    "                coincide += 1\n",
    "            else:\n",
    "                coincide = 0\n",
    "        if coincide > decision:\n",
    "            convergence = True\n",
    "        it += 1\n",
    "        return it, loglik, coincide, convergence\n",
    "\n",
    "    def Likelihood(self, EPS = 1e-12):\n",
    "        lambda_ij = np.einsum('ik,jq,kq-> ij', self.u, self.v, self.C)\n",
    "        return (self.A * np.log(lambda_ij + EPS)).sum() - lambda_ij.sum() \n",
    "\n",
    "    def update_optimal_parameters(self):\n",
    "        u_f = np.copy(self.u)\n",
    "        v_f = np.copy(self.v)\n",
    "        C_f = np.copy(self.C)\n",
    "        return u_f,v_f,C_f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af35540-6f43-488f-ba36-8dbed7ae6b59",
   "metadata": {},
   "source": [
    "## 1.2 VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffb1326-5037-44c0-94a5-91eb72b986d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMF_VI(object):\n",
    "    \n",
    "    def __init__(self, A, K=3):\n",
    "        self.A = A                 # data\n",
    "        self.K = K                 # number of communities\n",
    "        self.N = self.A.shape[0]   # number of nodes\n",
    "\n",
    "    def _init(self, prng):\n",
    "        # priors\n",
    "        self.a = 1\n",
    "        self.b = 1\n",
    "        self.c = 1\n",
    "        self.d = 1\n",
    "        \n",
    "        # random initialization\n",
    "        self.alpha_shp = prng.random_sample(size=(self.N,self.K)) + self.a\n",
    "        self.alpha_rte = prng.random_sample(size=(self.N,self.K)) + self.b\n",
    "        self.beta_shp = prng.random_sample(size=(self.N,self.K)) + self.c\n",
    "        self.beta_rte = prng.random_sample(size=(self.N,self.K)) + self.d\n",
    "\n",
    "    def fit(self, prng, N_real=15, max_iter=500, tol=0.1, decision=2, verbose=True):\n",
    "        maxElbo = - 1e12  # initialization of the maximum elbo\n",
    "\n",
    "        for r in range(N_real):\n",
    "            # random initialization\n",
    "            self._init(prng)\n",
    "\n",
    "            # convergence local variables\n",
    "            coincide, it = 0, 0\n",
    "            convergence = False\n",
    "\n",
    "            elbo_values = []  # keep track of the values of the elbo to plot\n",
    "            elbo = - 1e12  # initialization of the loglik\n",
    "\n",
    "            while not convergence and it < max_iter:\n",
    "                self._cavi()\n",
    "                \n",
    "                Eu, Elogu = compute_expectations(self.alpha_shp, self.alpha_rte)\n",
    "                Ev, Elogv = compute_expectations(self.beta_shp, self.beta_rte)\n",
    "\n",
    "                it, elbo, coincide, convergence = self.check_for_convergence_cavi(Eu, Elogu, Ev, Elogv, it, elbo, coincide,   \n",
    "                                                                          convergence, tolerance=tol, decision=decision)\n",
    "                elbo_values.append(elbo)\n",
    "            if verbose == True: print(f'Nreal = {r} - ELBO = {tl.fl(elbo)} - Best ELBO = {tl.fl(maxElbo)} - iterations = {it} - ')\n",
    "\n",
    "            if maxElbo < elbo:\n",
    "                alpha_shp_f,alpha_rte_f,beta_shp_f,beta_rte_f = self.update_optimal_parameters()\n",
    "                maxElbo = elbo\n",
    "                final_it = it\n",
    "                best_elbo_values = list(elbo_values)\n",
    "        \n",
    "        return alpha_shp_f, alpha_rte_f, beta_shp_f, beta_rte_f, best_elbo_values\n",
    "\n",
    "    def _cavi(self):\n",
    "        phi_ij = self.update_phi()\n",
    "\n",
    "        self.update_alphas(phi_ij)\n",
    "        phi_ij = self.update_phi()\n",
    "        self.update_betas(phi_ij)\n",
    "\n",
    "    def update_phi(self):\n",
    "        phi_ijk = np.einsum('ik,jk->ijk',np.exp(sp.psi(self.alpha_shp) - np.log(self.alpha_rte)), np.exp(sp.psi(self.beta_shp) - np.log(self.beta_rte)))\n",
    "        sumPhi = phi_ijk.sum(axis=-1)[:,:,np.newaxis]\n",
    "        sumPhi[sumPhi == 0] = 1\n",
    "        return phi_ijk / sumPhi\n",
    "    \n",
    "    def update_alphas(self, phi_ij):\n",
    "        self.alpha_shp = self.a + np.einsum('ij,ijk->ik', self.A,phi_ij)\n",
    "        self.alpha_rte = self.b + (self.beta_shp / self.beta_rte).sum(axis=0)[np.newaxis,:]\n",
    "        \n",
    "    def update_betas(self, phi_ij):\n",
    "        self.beta_shp = self.c + np.einsum('ij,ijk->jk', self.A,phi_ij)\n",
    "        self.beta_rte = self.d + (self.alpha_shp / self.alpha_rte).sum(axis=0)[np.newaxis,:]\n",
    "   \n",
    "    def check_for_convergence_cavi(self, Eu, Elogu, Ev, Elogv, it, elbo, coincide, convergence, tolerance=0.1,decision=2):\n",
    "        if it % 10 == 0:\n",
    "            old_elbo = elbo\n",
    "            elbo = self.Elbo(Eu, Elogu, Ev, Elogv)\n",
    "            if abs(elbo - old_elbo) < tolerance:\n",
    "                coincide += 1\n",
    "            else:\n",
    "                coincide = 0\n",
    "        if coincide > decision:\n",
    "            convergence = True\n",
    "        it += 1\n",
    "        return it, elbo, coincide, convergence\n",
    "\n",
    "    def Elbo(self, Eu, Elogu, Ev, Elogv):\n",
    "        bound = (self.A * np.log(np.einsum('ik,jk->ij',np.exp(Elogu),np.exp(Elogv)))).sum() - Eu.dot(Ev.T).sum()\n",
    "        bound += gamma_elbo_term(pa=self.a, pb=self.b, qa=self.alpha_shp, qb=self.alpha_rte).sum()\n",
    "        bound += gamma_elbo_term(pa=self.c, pb=self.d, qa=self.beta_shp, qb=self.beta_rte).sum()\n",
    "        return bound\n",
    "\n",
    "    def update_optimal_parameters(self):\n",
    "        alpha_shp = np.copy(self.alpha_shp)\n",
    "        alpha_rte = np.copy(self.alpha_rte)\n",
    "        beta_shp = np.copy(self.beta_shp)\n",
    "        beta_rte = np.copy(self.beta_rte)\n",
    "        return alpha_shp,alpha_rte,beta_shp,beta_rte\n",
    "    \n",
    "def compute_expectations(alpha, beta):\n",
    "    '''\n",
    "    Given x ~ Gam(alpha, beta), compute E[x] and E[log x]\n",
    "    '''    \n",
    "    return (alpha / beta , sp.psi(alpha) - np.log(beta))\n",
    "\n",
    "def gamma_elbo_term(pa, pb, qa, qb):\n",
    "        return sp.gammaln(qa) - pa * np.log(qb) + (pa - qa) * sp.psi(qa) + qa * (1 - pb / qb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79a0f30-2f89-44fe-ab21-79fbd7a2273d",
   "metadata": {},
   "source": [
    "# 2. Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adf3763-1628-4fd5-9238-fa4bc9646d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "indir = '../../../data/outdir/wto/'\n",
    "filename = 'wto_aob.csv'\n",
    "infile = f\"{indir}{filename}\"\n",
    "df = pd.read_csv(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90f106d-74f1-476d-8405-2effa4d45629",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = 'reporter_name'\n",
    "target = 'partner_name'\n",
    "weight = 'weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e199724-f393-4213-b16e-fedfc0526b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "undirected = True\n",
    "force_dense = True\n",
    "binary = True\n",
    "data = build_adjacency_from_file(\n",
    "    f\"{indir}{filename}\",\n",
    "    ego=source,\n",
    "    alter=target,\n",
    "    sep=\",\",\n",
    "    undirected=undirected,\n",
    "    force_dense=force_dense,\n",
    "    binary=binary,\n",
    "    header=0,\n",
    ")\n",
    "# Print the names of the coordinates in the namedtuple gdata\n",
    "print(data._fields)\n",
    "\n",
    "nodeLabel2Id = {k:i for i,k in enumerate(data.nodes)}\n",
    "nodeId2Label = {i:k for i,k in enumerate(data.nodes)}\n",
    "\n",
    "Y = data.adjacency_tensor\n",
    "\n",
    "plt.figure(figsize=(2,2))\n",
    "\n",
    "nmax = 500\n",
    "node_order = np.argsort(-Y[0].sum(axis=1))\n",
    "viz.plot_matrix(Y,node_order=node_order[:nmax],title=f\"Y\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee924ee-5281-4de8-8233-a6ff4435263f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = 10\n",
    "node_size = [np.log(data.graph_list[0].degree[i]) * ms + 20 for i in data.nodes]\n",
    "position = tl.get_custom_node_positions(data.graph_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75565c62-3012-4b56-9f02-d7c9be581918",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = data.adjacency_tensor[0]\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f5d047-5ddd-415b-b224-8109733c5ff5",
   "metadata": {},
   "source": [
    "Let's add some attribute based on country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b1f14e-349c-47aa-9015-3af6e5a4b7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_area = cc.continent['continent'].unique()\n",
    "nameShort2region = dict(zip(cc.continent['name_short'],cc.continent['continent']))\n",
    "nameShort2region['European Union'] = 'Europe'\n",
    "names_short = coconv.convert(names=data.nodes, to='name_short',not_found=None)\n",
    "nameRaw2Short = {data.nodes[i]: names_short[i] for i in range(len(names_short))}\n",
    "\n",
    "C = len(macro_area) + 1 # if 2: binary\n",
    "X_reg = np.zeros((len(data.nodes),C)).astype(int)\n",
    "\n",
    "for i,n in enumerate(data.nodes):\n",
    "    if nameRaw2Short[n] in nameShort2region:\n",
    "        r = nameShort2region[nameRaw2Short[n]]\n",
    "        idx = np.where(macro_area ==r)[0]\n",
    "        X_reg[i,idx] = 1\n",
    "    else:\n",
    "        print(n)\n",
    "        X_reg[i,-1] = 1\n",
    "        \n",
    "assert np.all(np.sum(X_reg,axis=1) == 1), np.where(np.sum(X_reg,axis=1) != 1)\n",
    "X_reg.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20ceed9-18bc-407e-8262-e3fcf94f7e05",
   "metadata": {},
   "source": [
    "# 3. Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2bd225-cd9a-40a9-b977-115427eca787",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 6\n",
    "u = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141f9bd7-858d-41d2-85af-f5885dc44948",
   "metadata": {},
   "source": [
    "## 3.1 EM + MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a31e7eb-9980-4750-976e-04af8c8338b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf_em = PMF_EM(A, K=K)\n",
    "u_em, v_em, C_em, best_loglik_values = pmf_em.fit(prng)\n",
    "\n",
    "u['em'] = u_em\n",
    "u['norm_em']= tl.normalize_nonzero_membership(u_em)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe8c342-186c-464e-8436-7d48829c09d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_L(best_loglik_values, int_ticks=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111bd8e3-af4c-4be3-8ccb-ea4874b0b0f9",
   "metadata": {},
   "source": [
    "## 3.2 VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c20022-d1d2-4866-8865-03494bfce460",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf_vi = PMF_VI(A, K=K)\n",
    "alpha_shp_vi, alpha_rte_vi, beta_shp_vi, beta_rte_vi, best_elbo_values = pmf_vi.fit(prng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529a5c61-0f84-405c-9875-da37a268318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.plot_L(best_elbo_values, int_ticks=True, ylab='ELBO')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219dad6e-fc2a-4f87-916f-c730abde16fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-28T10:29:56.586385Z",
     "iopub.status.busy": "2025-04-28T10:29:56.584886Z",
     "iopub.status.idle": "2025-04-28T10:29:56.620526Z",
     "shell.execute_reply": "2025-04-28T10:29:56.619958Z",
     "shell.execute_reply.started": "2025-04-28T10:29:56.586333Z"
    }
   },
   "source": [
    "## 3.3 MLE +EM + node attributes (MTCOV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0333db-d017-4dbc-8216-ad58b9a63580",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = {\n",
    "    \"assortative\": True,\n",
    "    \"end_file\": \"_mtcov\",\n",
    "    \"out_folder\": '../../../data/outdir/wto/',\n",
    "    \"out_inference\": True,\n",
    "    \"undirected\": True,\n",
    "    \"rseed\": 10\n",
    "}\n",
    "\n",
    "plot_loglik = False\n",
    "num_realizations = 20\n",
    "max_iter = 500\n",
    "decision = 1\n",
    "convergence_tol = 1e-3\n",
    "data = data._replace(design_matrix=X_reg)\n",
    "\n",
    "gamma = 0.7\n",
    "model = MTCOV(num_realizations=num_realizations, plot_loglik=plot_loglik,max_iter=max_iter,decision=decision,convergence_tol=convergence_tol)\n",
    "params_mtcov = model.fit(data, K=K, gamma=gamma, rng=np.random.default_rng(config_dict[\"rseed\"]), **config_dict)\n",
    "    \n",
    "u['mtcov'] = params_mtcov[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e84fad5-c954-4de4-a192-05df7770f665",
   "metadata": {},
   "source": [
    "# 4. Analyze results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5867cd4f-cb65-4d4c-beb4-5e112a61f384",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrib_label = 'continent'\n",
    "figsize= (16,10)\n",
    "\n",
    "fig, axs = plt.subplots(2,3, figsize=(16,6))\n",
    "\n",
    "algo = 'em'\n",
    "n_row = 0\n",
    "viz.plot_network(data,X_reg,ax=axs[n_row,0], title=f'Attribute {attrib_label}')\n",
    "viz.plot_network(data,u[algo],ax=axs[n_row,1], title = algo, plot_labels = False, threshold=0.1)\n",
    "q = tl.from_mixed_to_hard(u[algo])\n",
    "viz.plot_network(data,q,ax=axs[n_row,2], title = f'{algo} (hard)')\n",
    "\n",
    "algo = 'mtcov'\n",
    "n_row = 1\n",
    "viz.plot_network(data,X_reg,ax=axs[n_row,0], title=f'Attribute {attrib_label}')\n",
    "viz.plot_network(data,u[algo],ax=axs[n_row,1], title = algo, plot_labels = False, threshold=0.1)\n",
    "q = tl.from_mixed_to_hard(u[algo])\n",
    "viz.plot_network(data,q,ax=axs[n_row,2], title = f'{algo} (hard)')\n",
    "\n",
    "\n",
    "filename = tl.get_filename(f'wto_attribute_{attrib_label}_EM', lecture_id=lecture_id)\n",
    "filename = None\n",
    "tl.savefig(plt, outfile=filename, outdir=outdir_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557fa1ae-4680-436e-98b5-1ad4015c06c3",
   "metadata": {},
   "source": [
    "#### 4.1 How about VI ?  \n",
    "\n",
    "Recall that VI does not output automatically point estimates!  \n",
    "We need to extrapolate them from posterior distributions!  \n",
    "\n",
    "For instance, we can get them from taking **expectations** over the posteriors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f3f0b8-5b69-49ec-85e0-0f23b94df6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Eu_vi, Elogu_vi = compute_expectations(alpha_shp_vi,alpha_rte_vi)\n",
    "Ev_vi, Elogv_vi = compute_expectations(beta_shp_vi,beta_rte_vi)\n",
    "\n",
    "u['vi'] = Eu_vi\n",
    "u['norm_vi'] = tl.normalize_nonzero_membership(Eu_vi)\n",
    "assert np.all(np.allclose(np.sum(u['norm_vi'],axis=1),1))\n",
    "\n",
    "q_vi = np.argmax(u['norm_vi'], axis=1)  # extract hard communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e039679-06a5-4977-ba70-a38a7f9f5886",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_nodes = ['Norway','United Kingdom','European Union','Albania','Other Countries, n.e.s.']\n",
    "node_labels = {n: n for n in selected_nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221833bc-61e2-4249-b3b5-3b5c058ac1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrib_label = 'continent'\n",
    "figsize= (16,10)\n",
    "\n",
    "fig, axs = plt.subplots(1,3, figsize=(16,6))\n",
    "\n",
    "viz.plot_network(data,X_reg,position=position,ax=axs[0], title=f'Attribute {attrib_label}')\n",
    "viz.plot_network(data,u['vi'],position=position,ax=axs[1], title = r'VI', plot_labels = True, threshold=0.1,node_labels=node_labels)\n",
    "q = tl.from_mixed_to_hard(u['vi'])\n",
    "viz.plot_network(data,q,position=position,ax=axs[2], title = 'VI (hard)',node_labels=node_labels)\n",
    "\n",
    "\n",
    "filename = tl.get_filename(f'wto_attribute_{attrib_label}_VI', lecture_id=lecture_id)\n",
    "filename = None\n",
    "tl.savefig(plt, outfile=filename, outdir=outdir_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a72a63-874f-402b-971f-d04a4f2a1fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrib_label = 'continent'\n",
    "figsize= (16,10)\n",
    "\n",
    "fig, axs = plt.subplots(3,3, figsize=(24,18))\n",
    "\n",
    "viz.plot_network(data,X_reg,position=position,ax=axs[0,0], title=f'Attribute {attrib_label}', plot_labels = False)\n",
    "viz.plot_network(data,X_reg,position=position,ax=axs[1,0], title=f'Attribute {attrib_label}', plot_labels = False)\n",
    "viz.plot_network(data,X_reg,position=position,ax=axs[2,0], title=f'Attribute {attrib_label}', plot_labels = False)\n",
    "\n",
    "algo = 'vi'\n",
    "viz.plot_network(data,u[algo],position=position,ax=axs[0,1], title = algo, plot_labels = False, threshold=0.1)\n",
    "q = tl.from_mixed_to_hard(u[algo])\n",
    "viz.plot_network(data,q,position=position,ax=axs[0,2], title = f'{algo} (hard)')\n",
    "\n",
    "algo = 'em'\n",
    "viz.plot_network(data,u[algo],position=position,ax=axs[1,1], title = algo, plot_labels = False, threshold=0.1)\n",
    "q = tl.from_mixed_to_hard(u[algo])\n",
    "viz.plot_network(data,q,position=position,ax=axs[1,2], title = f'{algo} (hard)')\n",
    "\n",
    "algo = 'mtcov'\n",
    "viz.plot_network(data,u[algo],position=position,ax=axs[2,1], title = algo, plot_labels = False, threshold=0.1)\n",
    "q = tl.from_mixed_to_hard(u[algo])\n",
    "viz.plot_network(data,q,position=position,ax=axs[2,2], title = f'{algo} (hard)', plot_labels = False)\n",
    "\n",
    "\n",
    "filename = tl.get_filename(f\"WTO_MM\",lecture_id=lecture_id)\n",
    "filename = None\n",
    "tl.savefig(plt,outfile = filename,outdir = outdir_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16216e2-5a58-4c6f-8738-5227d20a33c4",
   "metadata": {},
   "source": [
    "### 4.2 Posterior distribution\n",
    "We can use posterior estimates to assess uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5369643c-a608-41cb-b27e-652131073a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fce7a4-b589-4563-b7f6-44dabd3d7d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 17 # example node id\n",
    "SAMPLE = 1000\n",
    "\n",
    "L = alpha_shp_vi.shape[1]\n",
    "fig, ax = plt.subplots(1,L,figsize=(16, 4), sharey=True,sharex=True)\n",
    "for i in range(L):\n",
    "    mean = alpha_shp_vi[idx,i] /alpha_rte_vi[0,i]\n",
    "    sns.histplot(prng.gamma(alpha_shp_vi[idx,i],  1. /alpha_rte_vi[0,i], size=SAMPLE),color=colors[i], kde=True,line_kws={'ls':'--'},alpha=0.1, ax=ax[i])\n",
    "    ax[i].axvline(x=mean,color=colors[i],ls='-',lw=1,alpha=0.8)\n",
    "    ylim = ax[i].get_ylim()\n",
    "    # ax[i].set_ylabel('P(k)')\n",
    "    ax[i].set_ylabel(r'$P(u_{ik})$')\n",
    "    ax[i].set_xlabel(r'$u_{ik}$')\n",
    "    ax[i].text(0.5,ylim[1]*0.85,f'k = {i}')\n",
    "\n",
    "title = nodeId2Label[idx]\n",
    "plt.title(f\"node = {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cf1a0f-97b1-4933-8a70-5601d1a93bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodeId2Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5434cc66-b60e-4650-9b14-555e176e06de",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1 # example node id\n",
    "SAMPLE = 1000\n",
    "\n",
    "L = alpha_shp_vi.shape[1]\n",
    "\n",
    "\n",
    "for with_text in [False,True]:\n",
    "    prng_tmp = np.random.RandomState(seed=seed)\n",
    "    fig, ax = plt.subplots(1,1,figsize=(8, 4))\n",
    "    for i in range(L):\n",
    "        mean = alpha_shp_vi[idx,i] /alpha_rte_vi[0,i]\n",
    "        std = alpha_shp_vi[idx,i] /(alpha_rte_vi[0,i] * alpha_rte_vi[0,i])\n",
    "        sns.histplot(prng_tmp.gamma(alpha_shp_vi[idx,i],  1. /alpha_rte_vi[0,i], size=SAMPLE),color=colors[i], kde=True,line_kws={'ls':'--'},alpha=0.3, ax=ax, label=f\"k={i}\")\n",
    "        ax.axvline(x=mean,color=colors[i],ls='-',lw=1,alpha=0.8)\n",
    "        ylim = ax.get_ylim()\n",
    "        xlim = ax.get_xlim()\n",
    "        # ax[i].set_ylabel('P(k)')\n",
    "        ax.set_ylabel(r'$P(u_{ik})$')\n",
    "        ax.set_xlabel(r'$u_{ik}$')\n",
    "\n",
    "    if with_text == True:\n",
    "        k = np.argmax(alpha_shp_vi[idx,:] /alpha_rte_vi[0,:])\n",
    "        mean = alpha_shp_vi[idx,k] /alpha_rte_vi[0,k]\n",
    "        std = np.sqrt(alpha_shp_vi[idx,k] /(alpha_rte_vi[0,k]*alpha_rte_vi[0,k]))\n",
    "        msg = f\"mean u_ik = {mean:.2f}\"\n",
    "        msg = f\"{msg}\\nstd u_ik = {std:.2f}\"\n",
    "        msg = f\"{msg}\\nVMR u_ik = {std*std/mean:.2f}\"\n",
    "        ax.text(xlim[1]* 0.5, ylim[1]*0.7, msg)\n",
    "\n",
    "    ax.set_xlim(0.01,xlim[1])\n",
    "    # ax.set_ylim(0.0,500)\n",
    "    \n",
    "    title = nodeId2Label[idx]\n",
    "    plt.title(f\"n = {title}\")\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    filename = tl.get_filename(f\"WTO_{title}_VI_{with_text}\",lecture_id=lecture_id)\n",
    "    filename = None\n",
    "    tl.savefig(plt,outfile = filename,outdir = outdir_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f652f4e-7123-4ef7-922b-e89ce83042cb",
   "metadata": {},
   "source": [
    "## 4.3 Model selection\n",
    "Which model performs the best?\n",
    "\n",
    "We need to apply model selection criteria to decide. Here we use cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae527008-112c-4233-b94a-168f561513c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "cv_mask = cvtl.extract_mask(data.adjacency_tensor.shape, seed = seed )\n",
    "cv_mask.keys(), cv_mask[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46da0603-73cf-4c92-ad4c-89d3442a68d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_cv =  { f: {} for f in cv_mask.keys()}\n",
    "K = 6\n",
    "for fold, mask in cv_mask.items():\n",
    "\n",
    "    data_cv = cvtl.get_df_train_test(df,data,cv_mask,fold=fold)\n",
    "    \n",
    "    algo = 'em'\n",
    "    pmf_em = PMF_EM(data_cv.adjacency_tensor[0], K=K)\n",
    "    params_cv[fold][algo] = pmf_em.fit(prng,verbose=False)\n",
    "\n",
    "    algo = 'vi'\n",
    "    pmf_vi = PMF_VI(data_cv.adjacency_tensor[0], K=K)\n",
    "    alpha_shp_f, alpha_rte_f, beta_shp_f, beta_rte_f, best_elbo_values = pmf_vi.fit(prng,verbose=False)\n",
    "    Eu_vi, Elogu_vi = compute_expectations(alpha_shp_vi,alpha_rte_vi)\n",
    "    Ev_vi, Elogv_vi = compute_expectations(beta_shp_vi,beta_rte_vi)\n",
    "    C_vi = np.ones((1,Eu_vi.shape[0],Ev_vi.shape[0]))\n",
    "    # params_cv[fold][algo] = (Eu_vi,Ev_vi,C_vi)\n",
    "    params_cv[fold][algo] = (alpha_shp_f, alpha_rte_f, beta_shp_f, beta_rte_f, best_elbo_values)\n",
    "\n",
    "    algo = 'mtcov'\n",
    "    gamma = 0.7\n",
    "    data_cv = data_cv._replace(design_matrix=X_reg)\n",
    "    model = MTCOV(num_realizations=num_realizations, plot_loglik=plot_loglik,max_iter=max_iter,decision=decision,convergence_tol=convergence_tol)\n",
    "    params_cv[fold][algo] = model.fit(data_cv, K=K, gamma=gamma, rng=np.random.default_rng(config_dict[\"rseed\"]), **config_dict)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dd5a30-cb1c-4868-a2d0-62d08f973145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mean_vi(alpha_shp_u,alpha_rte_u,alpha_shp_v,alpha_rte_v, method='geometric'):\n",
    "\n",
    "    Eu_vi, Elogu_vi = compute_expectations(alpha_shp_vi,alpha_rte_vi)\n",
    "    Ev_vi, Elogv_vi = compute_expectations(beta_shp_vi,beta_rte_vi)\n",
    "    \n",
    "    if method == 'geometric':\n",
    "        return np.einsum('ik,jk->ij',np.exp(Elogu_vi),np.exp(Elogv_vi))\n",
    "    else:\n",
    "        return np.einsum('ik,jk->ij',Eu_vi,Ev_vi)\n",
    "\n",
    "def compute_mean_lambda0_em(u,v,w):\n",
    "    if w.ndim == 3:\n",
    "        return np.einsum('ik,jq,akq->aij',u,v,w)\n",
    "    else:\n",
    "        if w.shape[0] == w.shape[1]:\n",
    "            Y = np.zeros((1,u.shape[0],v.shape[0]))\n",
    "            Y[0,:] = np.einsum('ik,jq,kq->ij',u,v,w)\n",
    "            return Y\n",
    "        else:\n",
    "            return np.einsum('ik,jk,ak->aij',u,v,w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8969c6-8283-429c-9727-4a95ae2e80bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_cv.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10431c64-b94d-43e0-aa2f-6cd2eb860177",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y_pred = {fold: {algo: compute_mean_lambda0_em(params_cv[fold][algo][0],params_cv[fold][algo][1],params_cv[fold][algo][2]) for algo in ['em','mtcov']} for fold in params_cv.keys()}\n",
    "\n",
    "method = 'geometric'\n",
    "for f in Y_pred.keys():\n",
    "    Y_pred[f]['vi'] = np.zeros_like(Y_pred[f]['mtcov'])\n",
    "    Y_pred[f]['vi'][0,:] = compute_mean_vi(params_cv[fold]['vi'][0],params_cv[fold]['vi'][1],params_cv[fold]['vi'][2],params_cv[fold]['vi'][3],method=method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7229ec5-d33c-4e99-8015-f17e2351aa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(2, len(params_cv[0].keys()),figsize=(8,6))\n",
    "\n",
    "fold = 2\n",
    "for i,algo in enumerate(params_cv[fold].keys()):\n",
    "    node_order = tl.extract_node_order(params_cv[fold]['em'][0])\n",
    "    viz.plot_matrix(data.adjacency_tensor,node_order=node_order,ax=axarr[0,i],title=f\"True: {algo}\",vmax = 1e-3,vmin=0)\n",
    "    viz.plot_matrix(Y_pred[fold][algo],node_order=node_order,ax=axarr[1,i],title=f\"Pred: {algo}\",vmin=0)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f59e1f5-bde7-4416-a5c3-9d78e7984e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.concat([cvtl.get_prediction_results(data, params_cv[fold], cv_mask,fold=fold,Y_pred=Y_pred[fold]) for fold in cv_mask.keys()])\n",
    "df_pred.head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840b378b-7046-4aaf-a3fe-41d2b00c90a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_mean = df_pred.groupby(by='algo').agg('mean').drop(columns=['fold']).reset_index()\n",
    "df_pred_std = df_pred.groupby(by='algo').agg('std').drop(columns=['fold']).reset_index()\n",
    "\n",
    "metrics = ['auc_test', \t'logL_test', \t'bce_test']\n",
    "df_pred_mean.style.background_gradient(subset=metrics,cmap=plt.cm.RdYlGn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f5f147-a153-48d0-ac2c-88c27edfca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = viz.default_colors[0]\n",
    "L = len(metrics)\n",
    "\n",
    "algos = list(df_pred_mean['algo'].unique())\n",
    "xticks = np.arange(len(algos))\n",
    "\n",
    "fig, axs = plt.subplots(1,L,figsize=(12,4),sharex=True)\n",
    "for i in range(L):\n",
    "    m = metrics[i]\n",
    "    axs[i].scatter(xticks,df_pred_mean[m],s=200,c=c, edgecolor='black')\n",
    "    axs[i].errorbar(xticks,df_pred_mean[m],yerr=df_pred_std[m], linewidth=1, capsize=4, capthick=1, color=c)\n",
    "    axs[i].set_xlabel('Model')\n",
    "    axs[i].set_ylabel(m)\n",
    "    axs[i].set_xticks(xticks,algos)\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "filename = tl.get_filename(f'wto_cv_example', lecture_id=lecture_id)\n",
    "filename = None\n",
    "tl.savefig(plt, outfile=filename, outdir=outdir_fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7283407b-914f-4e53-a66d-10be179726d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = viz.default_colors[0]\n",
    "\n",
    "m = 'auc_test'\n",
    "method1 = 'vi'\n",
    "methods = list(set(df_pred.algo.unique()).difference(set([method1])))\n",
    "L = len(methods)\n",
    "\n",
    "xlim = (df_pred[m].min() * 0.9,df_pred[m].max() * 1.05)\n",
    "mask1 = df_pred.algo == method1\n",
    "y_ref = df_pred[mask1].reset_index()\n",
    "\n",
    "fig, axs = plt.subplots(1,L,figsize=(8,3),sharex=True)\n",
    "for i in range(L):\n",
    "    mask2 = df_pred.algo == methods[i]\n",
    "    y_comp = df_pred[mask2].reset_index()\n",
    "\n",
    "    # mask_tot = mask1 & mask2\n",
    "    mask_c = y_ref[m] >= y_comp[m]\n",
    "    if np.sum(mask_c) > 0:\n",
    "        axs[i].scatter(y_ref[m][mask_c],y_comp[m][mask_c],s=100,c='b', edgecolor='black')\n",
    "        axs[i].scatter(y_ref[m][mask_c==False],y_comp[m][mask_c==False],s=100,c='r', edgecolor='black')\n",
    "    else:\n",
    "        axs[i].scatter(y_ref[m],y_comp[m],s=100,c='r', edgecolor='black')\n",
    "    axs[i].set_xlabel(f\"{m} {method1}\")\n",
    "    axs[i].set_ylabel(f\"{m} {methods[i]}\")\n",
    "\n",
    "    axs[i].set_xlim(xlim)\n",
    "    axs[i].set_ylim(xlim)\n",
    "\n",
    "    xs = np.linspace(xlim[0],xlim[1])\n",
    "    axs[i].plot(xs,xs,ls='--',alpha=0.8, color='darkgrey',lw=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# filename = tl.get_filename(f'wto_cv_example_fold_by_fold', lecture_id=lecture_id)\n",
    "filename = None\n",
    "tl.savefig(plt, outfile=filename, outdir=outdir_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef439cb8-2338-44bc-a24a-2436786b4af8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
